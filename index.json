[{"content":" The REx Hopper is now capable of balancing! However, it suffers from extreme oscillation at a relatively low frequency (about 8 Hz).\nThis looks like a controller issue\u0026ndash;perhaps even a simple matter of gain tuning\u0026ndash;until you look closer and slow the footage down. It\u0026rsquo;s a clear case of mechanical resonance\u0026ndash;notice how much the leg flexes back and forth.\nUnfortunately, I designed this leg with excessive focus on machining cost and ease of assembly, which led to the use of cantilevered joints and the use of, in retrospect, tiny bearings and shoulder screws. As it turns out, what may work for a simple quadruped doesn\u0026rsquo;t apply here. High bending stiffness in the lateral direction is crucial for an inverted reaction wheel pendulum.\nWith that lesson learned, I am now finishing up a much improved leg design. This design will not be concerned with cost, but rather purely optimal stiffness and strength-to-weight ratio. Within reason, of course. That means \u0026ldquo;clamshelled\u0026rdquo; aluminum links (to get hollow, near-circular cross-sections, which maximize second moment of area uniformly w.r.t. cross-sectional area) and massive clevis joints.\nHere\u0026rsquo;s a hint at what that looks like (still a W.I.P.):\nRendering. Cross-sectional rendering. (Of course, there are ways to circumvent this issue with model-based control. One can model the leg as a set of links with flexible joints. But it\u0026rsquo;s best to just fix this mechanically and leave that as a last resort.)\n","permalink":"https://bbokser.github.io/posts/2023-02-17/","summary":"The REx Hopper is now capable of balancing! However, it suffers from extreme oscillation at a relatively low frequency (about 8 Hz).\nThis looks like a controller issue\u0026ndash;perhaps even a simple matter of gain tuning\u0026ndash;until you look closer and slow the footage down. It\u0026rsquo;s a clear case of mechanical resonance\u0026ndash;notice how much the leg flexes back and forth.\nUnfortunately, I designed this leg with excessive focus on machining cost and ease of assembly, which led to the use of cantilevered joints and the use of, in retrospect, tiny bearings and shoulder screws.","title":"A Lesson in Mechanical Resonance"},{"content":"Over the years, I\u0026rsquo;ve witnessed countless failed projects (many of them my own) resulting from poor self-management. Here is how I recommend one approach hardware projects with the correct mentality.\n1. Don\u0026rsquo;t be Optimistic “I wonder if that would be an issue… eh, it’ll probably be fine.” “That could potentially fail, but it probably won’t.” No, It will never be \u0026ldquo;fine\u0026rdquo;. If a thought like that ever passes through your mind you need to STOP RIGHT THERE and correct whatever critical mistake you’re making. No joke. That is a GUARANTEED mistake. You are definitely overlooking something. Believe me when I say that I\u0026rsquo;m telling you this from experience.\nYou need to consider every possible way in which your design or solution could be flawed, and then realize that it is flawed. Everything that can go wrong will go wrong, and there are ways in which it will go wrong that you are not yet even educated enough to understand.\nBut all of these failure modes can be avoided if you are responsible enough to consider them and then do something about it.\n2. Don\u0026rsquo;t Avoid Unfamiliar Subjects “This is too hard, I’m not going to understand it. Let’s skip this part.” “I don’t have time to learn that.” “I don’t have time to consider that method.” Avoidance is an easy trap to fall into because it makes your job simpler and easier. The truth is that if you absolutely need to perform your research carefully and deliberately.\nSolving an engineering problem requires you to learn everything you can about the subject and underlying system. Take notes if you have to. Ask people questions.\nAt the very least, you need to know what you don\u0026rsquo;t know.\nWhat I have found is that most subjects are far easier to understand and quicker to learn than they appear, and yet at the same time they are far more complex than expected. What really holds people back from learning new subjects is not difficulty or time, but fear and sloth.\n3. Don\u0026rsquo;t Get Tunnel Vision “No, I’m sure I can make this work. I can’t consider other options at this point.” Too many times have I found myself repetitively performing the same test on a robot, hoping to get drastically better results by slightly modifying parameters. And almost every time, I was eventually forced to snap back to reality because the solution required going far beyond simply tuning parameters. This is tunnel vision. The human brain will do pretty much anything to avoid problem solving and creative thinking. It\u0026rsquo;s scary.\nDon’t get fixated on just one idea. Remember that there are other options, other paths to success. In fact, there is almost always a better way to do something.\n4. Be Wary of Productive Procrastination \u0026quot;I need to perfect this before I can move on to the next stage of the project.\u0026quot; Oftentimes when we become intimidated by one aspect of a project, we instead focus on perfecting some other aspect of the project, usually a subject with which we are more familiar and more comfortable working on. This, of course, exacerbates the problem further by wasting time. I\u0026rsquo;ve seen engineers make this mistake all too often, and it\u0026rsquo;s sad to watch.\nIn one case, I observed a team spend a month mathematically optimizing one attribute of a robot, a gear ratio, to avoid actually designing the robot. Why? They didn\u0026rsquo;t have enough design experience, but they were comfortable with the math. As a result, they ended up with even less time to learn how to design and build the robot. Needless to say, the project was a disaster. But they did have some fancy-looking equations.\nI myself have made this mistake every which way at some point in the past: I\u0026rsquo;ve used design to avoid math and used math to avoid design. I\u0026rsquo;ve used simulation to avoid hardware and used hardware to avoid simulation. Don\u0026rsquo;t make the same mistakes I did.\nThere’s nothing wrong with perfectionism, but there is always a time limit for completing a project and you need to budget your time appropriately. This is an extension of #2 (Avoidance), but in this case the avoidance is taken one step further. It\u0026rsquo;s an insidious, subconscious form of procrastination, one that allows us to avoid a task while still feeling smart and productive. Don’t fall for this trap.\n","permalink":"https://bbokser.github.io/posts/2023-01-24/","summary":"Over the years, I\u0026rsquo;ve witnessed countless failed projects (many of them my own) resulting from poor self-management. Here is how I recommend one approach hardware projects with the correct mentality.\n1. Don\u0026rsquo;t be Optimistic “I wonder if that would be an issue… eh, it’ll probably be fine.” “That could potentially fail, but it probably won’t.” No, It will never be \u0026ldquo;fine\u0026rdquo;. If a thought like that ever passes through your mind you need to STOP RIGHT THERE and correct whatever critical mistake you’re making.","title":"How to Not Fail at Hardware Projects"},{"content":"In late 2019, I designed a custom QDD gearbox. Then I designed a bipedal robot with said gearing. By early 2020 I was spending about an hour per day after work coding a controller for the bipedal robot I had designed. In that time I learned a great deal of Python, and my controls proficiency skyrocketed. Then I started grad school and had to put this project on hold for about six months. But now, over a year and a half later, I\u0026rsquo;ve finally achieved stable bipedal walking in simulation.\nOf course, as the saying goes, simulations are doomed to succeed. Successfully transferring Python code controlling a simulated robot to an embedded real-time controller running on a real robot is a monumental task on its own\u0026ndash;just ask Gerardo Bledt. In addition, I\u0026rsquo;ve been dealing with some sort of Bullet physics bug that causes the robot to fly into outer space, which is impeding further progress on the sim. I may have to switch to another simulator, such as RaiSim.\nAnd another thing: I\u0026rsquo;m not entirely satisfied with Spryped\u0026rsquo;s design. I believe many improvements can be made.\n","permalink":"https://bbokser.github.io/posts/2021-07-20/","summary":"In late 2019, I designed a custom QDD gearbox. Then I designed a bipedal robot with said gearing. By early 2020 I was spending about an hour per day after work coding a controller for the bipedal robot I had designed. In that time I learned a great deal of Python, and my controls proficiency skyrocketed. Then I started grad school and had to put this project on hold for about six months.","title":"Stable Bipedal Walking in Simulation"},{"content":"I have recently implemented a model predictive controller (MPC) to calculate the necessary reaction forces for a legged robot. The work presented here is based on this paper by Kim et al. If you don\u0026rsquo;t know what model predictive control is, I recommend this excellent explanation by Steve Brunton. I also found this guide to model predictive control with CasADI to be extremely helpful. CasADi is an open source nonlinear optimization tool which I\u0026rsquo;m using for MPC.\nHowever, I\u0026rsquo;m not entirely sure yet whether this code works the way it\u0026rsquo;s intended\u0026ndash;I\u0026rsquo;m not getting any error messages, but the force values I\u0026rsquo;m getting seem too low. If you spot anything wrong with my implementation, please let me know.\n​Here\u0026rsquo;s the code.\nPart 1. The Dynamics Formulation From the paper, we have the following discrete dynamics:\n$$ x(k+1) = A_kx(k) + B_k \\hat{f_k} + \\hat{g} $$\nwhere,\n$$ \\begin{equation} x = \\begin{bmatrix} \\theta^{\\top} \u0026amp; p^{\\top} \u0026amp; \\omega^{\\top} \u0026amp; \\dot{p}^{\\top} \\end{bmatrix}^{\\top} \\end{equation} $$\n$$ \\begin{equation} \\hat{f} = \\begin{bmatrix} f_1 \u0026amp; \u0026hellip; \u0026amp; f_n \\end{bmatrix}^{\\top} \\end{equation} $$\n$$ \\begin{equation} \\hat{g} = \\begin{bmatrix} 0_{1\\times{}3} \u0026amp; 0_{1\\times{}3} \u0026amp; 0_{1\\times{}3} \u0026amp; g^{\\top} \\end{bmatrix}^{\\top} \\end{equation} $$\n$$ \\begin{equation} A = \\begin{bmatrix} 1_{3\\times3} \u0026amp; 0_{3\\times3} \u0026amp; R_z(\\psi)\\Delta t \u0026amp; 0_{3\\times3} \\newline 0_{3\\times3} \u0026amp; 1_{3\\times3} \u0026amp; 0_{3\\times3} \u0026amp; 1_{3\\times3} \\Delta t \\newline 0_{3\\times3} \u0026amp; 0_{3\\times3} \u0026amp; 1_{3\\times3} \u0026amp; 0_{3\\times3} \\newline 0_{3\\times3} \u0026amp; 0_{3\\times3} \u0026amp; 0_{3\\times3} \u0026amp; 1_{3\\times3} \\end{bmatrix} \\end{equation} $$\n$$ \\begin{equation} B = \\begin{bmatrix} 0_{3\\times3} \u0026amp; 0_{3\\times3} \\newline 0_{3\\times3} \u0026amp; 0_{3\\times3} \\newline {}_GI^{-1}[r_1]_\\times \\Delta t \u0026amp; {}_GI^{-1}[r_1]_\\times \\Delta t \\newline 1_{3\\times3} \\Delta t /m \u0026amp; 1_{3\\times3} \\Delta t /m \\end{bmatrix} \\end{equation} $$ First off, you may be wondering what this notation means.\n$[r_1]_\\times$ refers to a skew-symmetric matrix. The $3\\times1$ vectors $r_1$ and $r_2$ (footstep positions) are converted into a $3\\times3$ matrix in order to perform a cross product operation with the inverse of the global inertia tensor.\n% matlab code r = [[0, -r_z, r_y]; [r_z, 0, -r_x]; [-r_y, r_x, 0]]; i_inv = sym(\u0026#39;i\u0026#39;, [3, 3]); mtimes(i_inv, r) A few more notes:\nThe state term $x$ is a $12\\times1$ vector composed of the angle, position, angular velocity, and velocity of the body w.r.t. to the global frame. In my case, there are only two legs, so there six scalar control values: $f_{1x}$, $f_{1y}$, $f_{1z}$, $f_{2x}$, $f_{2y}$, $f_{2z}$. The gravity term $\\hat{g}$ is a $12\\times1$ vector of zeros until the last term, which is the gravitational constant. $R_z$ is a $3\\times3$ rotation matrix for translating angular velocity from the global frame to the body frame. % matlab code syms theta_x theta_y theta_z p_x p_y p_z omega_x omega_y omega_z pdot_x ... pdot_y pdot_z f1_x f1_y f1_z f2_x f2_y f2_z ... dt i_inv r1x r1y r1z r2x r2y r2z mass gravity... i11 i12 i13 i21 i22 i23 i31 i32 i33... rz11 rz12 rz13 rz21 rz22 rz23 rz31 rz32 rz33 x = [[theta_x]; % states [theta_y]; [theta_z]; [p_x]; [p_y]; [p_z]; [omega_x]; [omega_y]; [omega_z]; [pdot_x]; [pdot_y]; [pdot_z]]; f = [[f1_x]; % controls [f1_y]; [f1_z]; [f2_x]; [f2_y]; [f2_z]]; g = [[0]; [0]; [0]; [0]; [0]; [0]; [0]; [0]; [0]; [0]; [0]; [gravity]]; A = [[1, 0, 0, 0, 0, 0, rz11*dt, rz12*dt, rz13*dt, 0, 0, 0]; [0, 1, 0, 0, 0, 0, rz21*dt, rz22*dt, rz23*dt, 0, 0, 0]; [0, 0, 1, 0, 0, 0, rz31*dt, rz32*dt, rz33*dt, 0, 0, 0]; [0, 0, 0, 1, 0, 0, 0, 0, 0, dt, 0, 0]; [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, dt, 0]; [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, dt]; [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]; [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]; [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]; [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]; [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]; [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]; B = [[0, 0, 0, 0, 0, 0]; [0, 0, 0, 0, 0, 0]; [0, 0, 0, 0, 0, 0]; [0, 0, 0, 0, 0, 0]; [0, 0, 0, 0, 0, 0]; [0, 0, 0, 0, 0, 0]; [(i12*r1z - i13*r1y)*dt, (-i11*r1z + i13*r1x)*dt, (i11*r1y - i12*r1x)*dt, ... (i12*r2z - i13*r2y)*dt, (-i11*r2z + i13*r2x)*dt, (i11*r2y - i12*r2x)*dt]; [(i22*r1z - i23*r1y)*dt, (-i21*r1z + i23*r1x)*dt, (i21*r1y - i22*r1x)*dt, ... (i22*r2z - i23*r2y)*dt, (-i21*r2z + i23*r2x)*dt, (i21*r2y - i22*r2x)*dt]; [(i32*r1z - i33*r1y)*dt, (-i31*r1z + i33*r1x)*dt, (i31*r1y - i32*r1x)*dt, ... (i32*r2z - i33*r2y)*dt, (-i31*r2z + i33*r2x)*dt, (i31*r2y - i32*r2x)*dt]; [dt/mass, 0, 0, dt/mass, 0, 0]; [0, dt/mass, 0, 0, dt/mass, 0]; [0, 0, dt/mass, 0, 0, dt/mass]]; x_next = mtimes(A, x) + mtimes(B, f) + g; The end result is a very long equation which will be used as a constraint for the QP. The states and controls are defined as symbolics, but other values such as the inertia tensor, rotation matrix, and foot positions are fed in as numerical values from sensor feedback.\n# python gravity = -9.807 dt = self.dt mass = self.mass x_next = [dt * omega_x * rz11 + dt * omega_y * rz12 + dt * omega_z * rz13 + theta_x, dt * omega_x * rz21 + dt * omega_y * rz22 + dt * omega_z * rz23 + theta_y, dt * omega_x * rz31 + dt * omega_y * rz32 + dt * omega_z * rz33 + theta_z, dt * pdot_x + p_x, dt * pdot_y + p_y, dt * pdot_z + p_z, dt * f1_x * (i12 * r1z - i13 * r1y) + dt * f1_y * (-i11 * r1z + i13 * r1x) + dt * f1_z * (i11 * r1y - i12 * r1x) + dt * f2_x * (i12 * r2z - i13 * r2y) + dt * f2_y * (-i11 * r2z + i13 * r2x) + dt * f2_z * (i11 * r2y - i12 * r2x) + omega_x, dt * f1_x * (i22 * r1z - i23 * r1y) + dt * f1_y * (-i21 * r1z + i23 * r1x) + dt * f1_z * (i21 * r1y - i22 * r1x) + dt * f2_x * (i22 * r2z - i23 * r2y) + dt * f2_y * (-i21 * r2z + i23 * r2x) + dt * f2_z * (i21 * r2y - i22 * r2x) + omega_y, dt * f1_x * (i32 * r1z - i33 * r1y) + dt * f1_y * (-i31 * r1z + i33 * r1x) + dt * f1_z * (i31 * r1y - i32 * r1x) + dt * f2_x * (i32 * r2z - i33 * r2y) + dt * f2_y * (-i31 * r2z + i33 * r2x) + dt * f2_z * (i31 * r2y - i32 * r2x) + omega_z, dt * f1_x / mass + dt * f2_x / mass + pdot_x, dt * f1_y / mass + dt * f2_y / mass + pdot_y, dt * f1_z / mass + dt * f2_z / mass + gravity + pdot_z] self.fn = cs.Function(\u0026#39;fn\u0026#39;, [theta_x, theta_y, theta_z, p_x, p_y, p_z, omega_x, omega_y, omega_z, pdot_x, pdot_y, pdot_z, f1_x, f1_y, f1_z, f2_x, f2_y, f2_z], x_next) # nonlinear mapping of function f(x,u) Part 2. The Objective Function $$ \\begin{align} \\min_{x,f} \\quad \u0026amp; \\sum^{m}_{k=0} \\lVert x(k+1) - x^{ref}(k+1) \\lVert_Q + \\lVert f_k\\lVert_R \\end{align} $$\nThe objective function is shown above.\n$$ \\lVert f(k)\\lVert_R $$\nLet\u0026rsquo;s start with this notation. What does it mean? Well, double bars represent a matrix norm. However, the R in subscript clues us into the fact that this is a special case of the matrix norm with an inner product. Q and R are weighing matrices and should be diagonal.\n$$ \\begin{equation} \\lVert f(k)\\lVert_R = \\sqrt{f(k)_R} = \\sqrt{f(k)Rf(k)} \\end{equation} $$\nHowever, I\u0026rsquo;m not sure what the purpose of the square root would be here. It seems to me that minimizing the square root of $f(x)$ is basically equivalent to minimizing $f(x)$ by itself, but more computationally expensive. In fact, running the code with the square root operation actually causes a QP is infeasible! error. As such, I\u0026rsquo;m leaving the square root operation out.\nSo, the objective function minimizes $x$ and $f$ (the state and control vectors) based on the difference between actual and reference state as well as the value of $f$, scaled to Q and R respectively, over $k$ time steps where $k$ is between 0 and $m$. Here, $m$ refers to the prediction horizon, which is chosen by the user.\nu = cs.SX.sym(\u0026#39;u\u0026#39;, self.n_controls, self.N) # decision variables, control action matrix st_ref = cs.SX.sym(\u0026#39;st_ref\u0026#39;, self.n_states + self.n_states) # initial and reference states x = cs.SX.sym(\u0026#39;x\u0026#39;, self.n_states, (self.N + 1)) # represents the states over the opt problem. obj = 0 # cs.SX(0) # objective function constr = [] # constraints vector Q = np.zeros((12, 12)) # state weighing matrix Q[0, 0] = 1 Q[1, 1] = 1 Q[2, 2] = 1 Q[3, 3] = 1 Q[4, 4] = 1 Q[5, 5] = 1 Q[6, 6] = 1 Q[7, 7] = 1 Q[8, 8] = 1 Q[9, 9] = 1 Q[10, 10] = 1 Q[11, 11] = 1 R = np.zeros((6, 6)) # control weighing matrix R[0, 0] = 1 R[1, 1] = 1 R[2, 2] = 1 R[3, 3] = 1 R[4, 4] = 1 R[5, 5] = 1 st = x[:, 0] # initial state constr = cs.vertcat(constr, st - st_ref[0:self.n_states]) # initial condition constraints # compute objective and constraints for k in range(0, self.N): st = x[:, k] # state con = u[:, k] # control action # calculate objective obj = obj + cs.mtimes(cs.mtimes((st - st_ref[self.n_states:(self.n_states * 2)]).T, Q), st - st_ref[self.n_states:(self.n_states * 2)])) \\ + cs.mtimes(cs.mtimes(con.T, R), con)) Both my Q and R are identity matrices right now, as I have not yet tuned them.\nPart 3. The Constraints Vector In the same for loop, we can now add the constraints vector. For each iteration of the loop, the discrete dynamics equation from Part 1 is subtracted from the next state vector, $x(k+1)$.\nfor k in range(0, self.N): # ... st_next = x[:, k + 1] f_value = self.fn(st[0], st[1], st[2], st[3], st[4], st[5], st[6], st[7], st[8], st[9], st[10], st[11], con[0], con[1], con[2], con[3], con[4], con[5]) st_n_e = np.array(f_value) constr = cs.vertcat(constr, st_next - st_n_e) # compute constraints There are more constraints, however. Namely, friction cone constraints, governed by friction of the feet with the ground. As stated in the paper:\n$$ \\begin{equation} \\vert{}f_x\\vert{} \\leq \\mu f_z \\end{equation} $$\n$$ \\begin{equation} \\vert{}f_x\\vert{} \\leq \\mu f_z \\end{equation} $$\n$$ \\begin{equation} f_z \u0026gt; 0 \\end{equation} $$\nHere\u0026rsquo;s my implementation below. Both the $F_x$ and $F_y$ inequalities must be repeated due to the absolute value function. $F_z$ is not required here because it\u0026rsquo;s extremely simple and can be implemented as an input constraint.\n# add additional constraints for k in range(0, self.N): constr = cs.vertcat(constr, u[0, k] - self.mu * u[2, k]) # f1x - mu*f1z constr = cs.vertcat(constr, -u[0, k] - self.mu * u[2, k]) # -f1x - mu*f1z constr = cs.vertcat(constr, u[1, k] - self.mu * u[2, k]) # f1y - mu*f1z constr = cs.vertcat(constr, -u[1, k] - self.mu * u[2, k]) # -f1y - mu*f1z constr = cs.vertcat(constr, u[3, k] - self.mu * u[5, k]) # f2x - mu*f2z constr = cs.vertcat(constr, -u[3, k] - self.mu * u[5, k]) # -f2x - mu*f2z constr = cs.vertcat(constr, u[4, k] - self.mu * u[5, k]) # f2y - mu*f2z constr = cs.vertcat(constr, -u[4, k] - self.mu * u[5, k]) # -f2y - mu*f2z Part 4. Problem Setup The solver used here is qpOASES. The optimization variables (in this case, the state and controls), objective function, constraint functions, and reference state are declared as shown. It is important to specify a bound tolerance and termination tolerance.\nopt_variables = cs.vertcat(cs.reshape(x, n_states * (self.N + 1), 1), cs.reshape(u, n_controls * self.N, 1)) qp = {\u0026#39;x\u0026#39;: opt_variables, \u0026#39;f\u0026#39;: obj, \u0026#39;g\u0026#39;: constr, \u0026#39;p\u0026#39;: st_ref} opts = {\u0026#39;print_time\u0026#39;: 0, \u0026#39;error_on_fail\u0026#39;: 0, \u0026#39;printLevel\u0026#39;: \u0026#34;low\u0026#34;, \u0026#39;boundTolerance\u0026#39;: 1e-6, \u0026#39;terminationTolerance\u0026#39;: 1e-6} solver = cs.qpsol(\u0026#39;S\u0026#39;, \u0026#39;qpoases\u0026#39;, qp, opts) Part 5. Upper and Lower Bounds The upper and lower bounds for the constraint vector still needs to be set. The dynamics equation is set up as an equality constraint, so the upper and lower bounds are both zero. The initial condition constraint is also an equality constraint, since the first state vector must be equal to the input state vector. The rest of the constraints have a lower bound close to infinity.\nc_length = np.shape(constr)[0] o_length = np.shape(opt_variables)[0] lbg = list(itertools.repeat(-1e10, c_length)) # inequality constraints: big enough to act like infinity lbg[0:(self.N + 1)] = itertools.repeat(0, self.N + 1) # IC + dynamics equality constraint ubg = list(itertools.repeat(0, c_length)) # inequality constraints Constraints for the optimization variables are set separately. This is where the friction cone restraint for $F_z$ comes into play. The reaction force perpendicular to the ground (assumed flat) must be upward, because the robot can only push itself away from the ground rather than pull itself toward the ground. Therefore, the lower bound on all $F_z$ is 0.\nAdditionally, the MPC must check if each leg is actually in contact with the ground when calculating forces for it. If that leg is not in contact, all bounds are set equal to zero.\n# constraints for optimization variables lbx = list(itertools.repeat(-1e10, o_length)) # input inequality constraints ubx = list(itertools.repeat(1e10, o_length)) # input inequality constraints dyn_len = self.n_states * (self.N + 1) lbx[(dyn_len + 2)::3] = [0 for i in range(20)] # lower bound on all f1z and f2z if c_l == 0: # if left leg is not in contact... don\u0026#39;t calculate output forces for that leg. ubx[(self.n_states * (self.N + 1))::6] = [0 for i in range(10)] # upper bound on all f1x ubx[(self.n_states * (self.N + 1) + 1)::6] = [0 for i in range(10)] # upper bound on all f1y lbx[(self.n_states * (self.N + 1))::6] = [0 for i in range(10)] # lower bound on all f1x lbx[(self.n_states * (self.N + 1) + 1)::6] = [0 for i in range(10)] # lower bound on all f1y ubx[(self.n_states * (self.N + 1) + 2)::6] = [0 for i in range(10)] # upper bound on all f1z if c_r == 0: # if right leg is not in contact... don\u0026#39;t calculate output forces for that leg. ubx[(self.n_states * (self.N + 1) + 3)::6] = [0 for i in range(10)] # upper bound on all f2x ubx[(self.n_states * (self.N + 1) + 4)::6] = [0 for i in range(10)] # upper bound on all f2y lbx[(self.n_states * (self.N + 1) + 3)::6] = [0 for i in range(10)] # lower bound on all f2x lbx[(self.n_states * (self.N + 1) + 4)::6] = [0 for i in range(10)] # lower bound on all f2y ubx[(self.n_states * (self.N + 1) + 5)::6] = [0 for i in range(10)] # upper bound on all f2z Part 6. Solving Firstly, initial values must be fed into the solver.\nI\u0026rsquo;ve set the initial values for my control inputs as an array of zeros, although I\u0026rsquo;m wondering if that should really be the last set of control inputs applied.\nThe initial values for the state are pulled in and calculated from the simulator. This $12\\times1$ array is repeated $N+1$ times, where $N$ is the prediction horizon, in order to fill the entire array including future states.\nu0 = np.zeros((self.N, self.n_controls)) # six control inputs X0 = np.matlib.repmat(x_in, 1, self.N + 1).T # initialization of the state\u0026#39;s decision variables parameters = cs.vertcat(x_in, x_ref) # set values of parameters vector # init value of optimization variables x0 = cs.vertcat(np.reshape(X0.T, (self.n_states * (self.N + 1), 1)), np.reshape(u0.T, (self.n_controls * self.N, 1))) Finally, the initial states, bounds, and parameters are plugged into the solver. The controls vector is pulled from the solution, and the first row of optimized control values is returned. The rest of the values (representing future time steps) are ignored.\nsol = solver(x0=x0, lbx=lbx, ubx=ubx, lbg=lbg, ubg=ubg, p=parameters) solu = np.array(sol[\u0026#39;x\u0026#39;][self.n_states * (self.N + 1):]) u = np.reshape(solu.T, (self.n_controls, self.N)).T # get controls from the solution u_cl = u[0, :] # ignore rows other than first row return u_cl ","permalink":"https://bbokser.github.io/posts/2020-10-12/","summary":"I have recently implemented a model predictive controller (MPC) to calculate the necessary reaction forces for a legged robot. The work presented here is based on this paper by Kim et al. If you don\u0026rsquo;t know what model predictive control is, I recommend this excellent explanation by Steve Brunton. I also found this guide to model predictive control with CasADI to be extremely helpful. CasADi is an open source nonlinear optimization tool which I\u0026rsquo;m using for MPC.","title":"Model Predictive Control for a Legged Robot"},{"content":"I\u0026rsquo;m currently working on the Python code to control a simulated version of my latest bipedal robot design in PyBullet. My focus over the past few weeks was getting the operational space control to work (many thanks to Travis DeWolf\u0026rsquo;s incredibly helpful blog). After finally getting it to work properly, I have decided to share my math in the hopes of providing a useful example for anyone else having trouble with this. There really aren\u0026rsquo;t enough resources on the internet that explain this in a succinct manner.\nAn earlier mechanical design. Kinematic diagram. Solving for the transformation matrices and centers of motion correctly is the trickiest part of the process, and deceptively so. For more information on how to set up the transformation matrices, I recommend this Youtube tutorial and this blog post.\nI find it easiest to solve for the transformation matrices by \u0026ldquo;stringing\u0026rdquo; the robot out, as shown below, such that all of the joints\u0026rsquo; coordinate systems are oriented the same way. This saves you from having to perform additional linear algebra operations, which would raise your chances of making a mistake.\nShown below are the transformation matrices. The first transformation represents an x-axis rotation. See the first joint in the kinematic diagram above for reference. Transformations (2) through (4) are z-axis rotations. Despite the z-axis pointing up in the world coordinate system, the default angle (90 degrees) for the first x-axis rotation points the z-axis of the second through fourth joints parallel to the y-axis of the WCS.\n$$ \\begin{equation} {}_{org}^0 T = \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; \\cos{(q_{0})} \u0026amp; - \\sin{(q_{0})} \u0026amp; L_{0}\\cos{(q_{0})} \\newline 0 \u0026amp; \\sin{(q_{0})} \u0026amp; \\cos{(q_{0})} \u0026amp; L_{0}\\sin{(q_{0})} \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix}\t\\end{equation} $$ $$ \\begin{equation} {}_0^1 T = \\begin{bmatrix} \\cos{(q_{1} )} \u0026amp; - \\sin{(q_{1} )} \u0026amp; 0 \u0026amp; -L_{1} \\sin{(q_{1} )} \\newline \\sin{(q_{1} )} \u0026amp; \\cos{(q_{1} )} \u0026amp; 0 \u0026amp; L_{1} \\cos{(q_{1} )} \\newline 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} \\end{equation} $$ $$ \\begin{equation} {}_1^2 T = \\begin{bmatrix} \\cos{(q_{2} )} \u0026amp; - \\sin{(q_{2} )} \u0026amp; 0 \u0026amp; -L_{2} \\sin{(q_{2} )} \\newline \\sin{(q_{2} )} \u0026amp; \\cos{(q_{2} )} \u0026amp; 0 \u0026amp; L_{2} \\cos{(q_{2} )} \\newline 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} \\end{equation} $$ $$ \\begin{equation} {}_2^3 T = \\begin{bmatrix} \\cos{(q_{3} )} \u0026amp; - \\sin{(q_{3} )} \u0026amp; 0 \u0026amp; -L_{3} \\sin{(q_{3} )} \\newline \\sin{(q_{3} )} \u0026amp; \\cos{(q_{3} )} \u0026amp; 0 \u0026amp; L_{3} \\cos{(q_{3} )} \\newline 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} \\end{equation} $$ Next, the locations for the centers of mass at each link are found, where $l_0$, $l_1$, $l_2$, and $l_3$ represent the distance of the center of mass from the base joint of each link, along a line connecting the base joint to the next joint. Keep in mind that the centers of mass may not be located directly along a line from one joint to the next in any given robot link, and that in this case I am able to make this approximation for the purpose of mathematical simplicity.\n$$ \\begin{equation} com_0 = \\begin{bmatrix} 0 \\newline l_{0} \\cos{(q_{0} )} \\newline l_{0} \\sin{(q_{0} )} \\newline 1 \\end{bmatrix} \\end{equation} $$\n$$ \\begin{equation} com_1 = \\begin{bmatrix} {-l_{1} \\sin{(q_{1} )}} \\newline l_{1} \\cos{(q_{1} )} \\newline 0 \\newline 1 \\end{bmatrix} \\end{equation} $$\n$$ \\begin{equation} com_2 = \\begin{bmatrix} -l_{2} \\sin{(q_{2} )} \\newline l_{2} \\cos{(q_{2} )} \\newline 0 \\newline 1 \\end{bmatrix} \\end{equation} $$\n$$ \\begin{equation} com_3 = \\begin{bmatrix} -l_{3} \\sin{(q_{3} )} \\newline l_{3} \\cos{(q_{3} )} \\newline 0 \\newline 1 \\end{bmatrix} \\end{equation} $$\nThe end-effector offset (Equation 9) should also be kept in mind, but in my case I don\u0026rsquo;t need an offset from the end-effector. As such, I\u0026rsquo;m expressing it as zero.\n$$ \\begin{equation} x_{ee} = \\begin{bmatrix} 0 \\newline 0 \\newline 0 \\newline 1 \\end{bmatrix} \\end{equation} $$\nNext, I solved for the full transformation matrices from the origin to each joint. This isn\u0026rsquo;t necessary for the first joint, because it\u0026rsquo;s already in the base coordinate system.\n$$ \\begin{equation} _{org}^1 T = _{org}^0 T _0^1 T \\end{equation} $$\n$$ \\begin{equation} _{org}^2 T = _{org}^0 T _0^1 T _1^2 T \\end{equation} $$\n$$ \\begin{equation} _{org}^3 T = _{org}^0 T _0^1 T _1^2 T _2^3 T \\end{equation} $$\nNow, the Jacobian for each COM and the end-effector can be found as a matrix of its partial derivatives with respect to each joint qᵢ. Both linear and angular velocities must be accounted for, so I have $x$, $y$, $z$, $\\omega_x$, $\\omega_y$, $\\omega_z$ to deal with.\n$$ \\begin{equation} Jacobian = \\begin{bmatrix} \\frac{\\partial x}{\\partial q_0} \u0026amp; \\frac{\\partial x}{\\partial q_1} \u0026amp; \\frac{\\partial x}{\\partial q_2} \u0026amp; \\frac{\\partial x}{\\partial q_3} \\newline \\frac{\\partial y}{\\partial q_0} \u0026amp; \\frac{\\partial y}{\\partial q_1} \u0026amp; \\frac{\\partial y}{\\partial q_2} \u0026amp; \\frac{\\partial y}{\\partial q_3} \\newline \\frac{\\partial z}{\\partial q_0} \u0026amp; \\frac{\\partial z}{\\partial q_1} \u0026amp; \\frac{\\partial z}{\\partial q_2} \u0026amp; \\frac{\\partial z}{\\partial q_3} \\newline \\frac{\\partial \\omega_x}{\\partial q_0} \u0026amp; \\frac{\\partial \\omega_x}{\\partial q_1} \u0026amp; \\frac{\\partial \\omega_x}{\\partial q_2} \u0026amp; \\frac{\\partial \\omega_x}{\\partial q_3} \\newline \\frac{\\partial \\omega_y}{\\partial q_0} \u0026amp; \\frac{\\partial \\omega_y}{\\partial q_1} \u0026amp; \\frac{\\partial \\omega_y}{\\partial q_2} \u0026amp; \\frac{\\partial \\omega_y}{\\partial q_3} \\newline \\frac{\\partial \\omega_z}{\\partial q_0} \u0026amp; \\frac{\\partial \\omega_z}{\\partial q_1} \u0026amp; \\frac{\\partial \\omega_z}{\\partial q_2} \u0026amp; \\frac{\\partial \\omega_z}{\\partial q_3} \\newline \\end{bmatrix} \\end{equation} $$ So far I haven\u0026rsquo;t explained angular velocity. This I have solved separately, and it\u0026rsquo;s quite simple as long as your robot is serial and doesn\u0026rsquo;t have spherical joints. The partial derivative for the angular velocity w.r.t. each joint is expressed as 1 if that joint rotates along that axis, and 0 if it doesn\u0026rsquo;t. For example, in J₀ (Equation 14), joint q₀ rotates around the x axis, so the partial derivative of $\\omega_x$ w.r.t. $q_0$ is 1. In $J_1$ (Equation 15), joint $q_1$ rotates about the z axis, so the partial derivative of $\\omega_z$ w.r.t. $q_1$ is 1.\n$$ \\begin{equation} J_0 = Jacobian(com_0) = \\begin{bmatrix} 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline - l_{0} \\sin{(q_{0} )} \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline l_{0} \\cos{(q_{0} )} \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix} \\end{equation} $$ I can only show the first two Jacobians here, as the rest are too long to fit on the screen. You\u0026rsquo;ll notice that the Jacobians for the centers of motion of each link ($J_0$, $J_1$, $J_2$, and $J_3$) are calculated as a function of the transformation matrix from the link\u0026rsquo;s base joint to the origin multiplied by that link\u0026rsquo;s center of motion. This confused me the first time around, and I don\u0026rsquo;t want you, the reader, to make the same mistake.\nFor example, in the case of $J_1$ (the Jacobian for the second link), the transformation matrix from joint 0 to the world coordinate frame (origin) is multiplied by $com_1$, the center of motion of the link between joints 0 and 1 (the first and second joints, so the second link).\nFor $J_0$ (the Jacobian for the first link), no transformation matrix is required because the first joint ($q_0$) is already in the base coordinate system.\nI\u0026rsquo;m probably just confusing you more because my joint indexing starts at zero, but that\u0026rsquo;s for programming purposes and is standard\u0026hellip;\n$$ J_1 = Jacobian(_{org}^0 T com_1) = $$\n$$ \\begin{equation} \\begin{bmatrix} 0 \u0026amp; - l_{1} \\cos{(q_{1} )} \u0026amp; 0 \u0026amp; 0 \\newline - (L_{0} + l_{1} \\cos{(q_{1} )}) \\sin{(q_{0} )} \u0026amp; - l_{1} \\sin{(q_{1} )} \\cos{(q_{0} )} \u0026amp; 0 \u0026amp; 0 \\newline (L_{0} + l_{1} \\cos{(q_{1} )}) \\cos{(q_{0} )} \u0026amp; - l_{1} \\sin{(q_{0} )} \\sin{(q_{1} )} \u0026amp; 0 \u0026amp; 0 \\newline 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix} \\end{equation} $$\n$$ \\begin{equation} J_2 = Jacobian(_{org}^1 T com_2) \\end{equation} $$\n$$ \\begin{equation} J_3 = Jacobian(_{org}^2 T com_3) \\end{equation} $$\n$$ \\begin{equation} J_{EE} = Jacobian(_{org}^3 T x_{ee}) \\end{equation} $$ So there you have it. After several headaches, I was able to verify that this setup works in simulation. The chief cause of my problems was that I had solved for the transformation matrices incorrectly! Everything else is easy\u0026ndash;though it looks intimidating, all of the symbolic math can be computationally solved by Matlab/Octave. Just remember\u0026hellip;\n$$ \\begin{equation} \\text{garbage}_{in} = \\text{garbage}_{out} \\end{equation} $$ ","permalink":"https://bbokser.github.io/posts/2020-05-04/","summary":"I\u0026rsquo;m currently working on the Python code to control a simulated version of my latest bipedal robot design in PyBullet. My focus over the past few weeks was getting the operational space control to work (many thanks to Travis DeWolf\u0026rsquo;s incredibly helpful blog). After finally getting it to work properly, I have decided to share my math in the hopes of providing a useful example for anyone else having trouble with this.","title":"Solving for the Jacobians of a Robot Leg"}]