[{"content":"So I made my own alarm clock.\nIt has no snooze button and no off button. It also has a backup battery in case it gets unplugged, and there\u0026rsquo;s no way to remove the battery without a hex key.\nActually deactivating the alarm requires hitting a remote key fob. The idea is to hide the key fob as far away from your bed as possible. Obviously this is more effective the larger your home is.\nTo close loopholes, you also can\u0026rsquo;t change the alarm or even the date or time without hitting the remote switch.\nDetails Schematic. It\u0026rsquo;s in vector format, so you can zoom way in. A quick list of features:\nTime, date, and two alarms Humidity and temperature display LED brightness setting Celsius vs Fahrenheit setting STEMMA-QT/Qwiic breakout 2.54mm pitch breakout with 3.3V, GND, 5x GPIOs, and 3x ADC The microcontroller is an RP2040 and the code is written in CircuitPython. I found CircuitPython simultaneously really convenient and extremely limiting.\nThe github repo is here if you want to learn more. It\u0026rsquo;s fully open source. Electrical (KiCAD), mechanical (STEP), and software.\nThe Story At first, this was just something I wanted for myself, and so I cobbled something together out of parts I had lying around. That was the V0. Then I decided to do a PCB, and made the V1. The V1 had a bunch of issues, but the V2 functioned the way I wanted it to.\nI liked the V2 so much that I wanted to share the design with my friends. So I decided to make 10 of the V3, with the intent of giving them out to people I knew.\nThis turned out to be a lot more trouble than I had anticipated.\nFirst off, I didn\u0026rsquo;t want to deal with JLCPCB\u0026rsquo;s annoying MOQ requirements for PCBA\u0026ndash;they were going to force me to buy way more parts than I needed (and their weird consignment system seemed like overkill)\u0026ndash;so I only had the boards ordered with the \u0026ldquo;basic\u0026rdquo; components assembled (mostly just resistors and caps). This ended up being the worst of both worlds. I was ordering PCBA but also tediously soldering every board. Would not recommend.\nThen it turned out I had accidentally shorted one of the pushbuttons in the schematic. This had to be fixed with Kynar wire on all ten V3s. You can see that in the open shot below.\nNext, I found out that one of the battery holders had arrived with the positive and negative terminals on its connector reversed. What the heck! I didn\u0026rsquo;t discover this until I had already plugged it in. Fortunately, the design includes reverse voltage protection.\nFinally, when I thought the ordeal was over, half my RF receivers bricked on the same day. It turned out that they were knockoffs\u0026ndash;I had naively ordered them from AliExpress rather than the official website. They don\u0026rsquo;t even look the same. Outrageous!\nAnyway, it\u0026rsquo;s finished! And now I get to ship these out to my friends.\nLast edited 2025-08-04.\n","permalink":"https://bbokser.github.io/posts/2025-05-04/","summary":"\u003cp\u003eSo I made my own alarm clock.\u003c/p\u003e\n\u003cp\u003eIt has no snooze button and no off button. It also has a backup battery in case it gets unplugged, and there\u0026rsquo;s no way to remove the battery without a hex key.\u003c/p\u003e\n\u003cp\u003eActually deactivating the alarm requires hitting a remote key fob. The idea is to hide the key fob as far away from your bed as possible. Obviously this is more effective the larger your home is.\u003c/p\u003e","title":"A Less Forgiving Alarm Clock"},{"content":"In this post, we will add 1-dimensional coulomb friction to our simulation.\nFirst off, we\u0026rsquo;re going to need to allow movement in the horizontal direction. Our new state-space system will be a 2-dimensional system subject to both horizontal and vertical forces.\n$$ \\begin{equation} \\underbrace{\\begin{bmatrix} \\dot{x} \\\\ \\dot{z} \\\\ \\ddot{x} \\\\ \\ddot{z} \\end{bmatrix}}_{\\dot{X}} = \\underbrace{\\begin{bmatrix} 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ \\end{bmatrix}}_A \\underbrace{\\begin{bmatrix} x \\\\ z \\\\ \\dot{x} \\\\ \\dot{z} \\end{bmatrix}}_X \u0026#43; \\underbrace{\\begin{bmatrix} 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \\\\ \\frac{1}{m} \u0026amp; 0 \\\\ 0 \u0026amp; \\frac{1}{m} \\end{bmatrix}}_B \\underbrace{\\begin{bmatrix} f_x \\\\ f_z \\end{bmatrix}}_F \u0026#43; \\underbrace{\\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ -9.81 \\end{bmatrix}}_G \\end{equation} $$ Modeling Friction For 1-dimensional Coulomb friction, our friction force, $f_x$, is related to our vertical force $f_z$ by the following equation.\n$$ \\begin{equation} f_x = -\\mu f_z \\text{sign}(\\dot{x}) \\end{equation} $$\nAlthough you are probably already familiar with this equation, it\u0026rsquo;s deceptively difficult to model because it has several discontinuities. Check out what happens when an object slides to a stop:\nAs your object transitions from slipping to sticking, your acceleration $\\ddot{x}$ and friction force $f_x$ jump from constant values to zero. Budge the object in either direction and your friction force will shoot to a constant positive or negative value on a dime.\nBecause the relationship between friction and speed is tricky to model, we need to split this equation up a bit. Firstly, we define the magnitude of the friction force as follows.\n$$ \\begin{equation} ||f_x|| \\leq \\mu f_z \\end{equation} $$\nYou may be wondering how the magnitude of friction can be less than $\\mu f_z$ all of a sudden. Well think about what happens when the object stops. Its friction force can\u0026rsquo;t be proportional to the normal force anymore, or it would never stop moving! To enforce $f_x = 0$ when the object is stopped, we\u0026rsquo;re going to use a Lagrange multiplier, $\\lambda_k$, which represents the magnitude of the tangential ground velocity at timestep $k$.\n$$ \\begin{equation} \\lambda_k (\\mu f_z - ||f_x||) = 0 \\end{equation} $$\nAs you can see, we are constraining $f_x$ so that it can only be zero when the tangential velocity is zero.\nThe magnitude of tangential velocity $\\lambda_k$ is defined as shown. Eq. (5) is pulling double duty because it also enforces that $f_x$ must point in the opposite direction of $\\dot{x}_k$.\n$$ \\begin{equation} \\dot{x}_k + \\lambda_k \\frac{f_x}{||f_x||} = 0 \\end{equation} $$\n$$ \\begin{equation} \\lambda_k \\geq 0 \\end{equation} $$\nThe Optimization Problem Just like last time, there are a few hacks we have to use to make the optimization problem run well with IPOPT. Firstly, we have to define a \u0026ldquo;smooth norm\u0026rdquo; function, $\\text{snorm}(x)$, as shown, to make norm functions less discontinuous. $\\epsilon$ is an arbitrarily small constant that we will make equal to the solver tolerance.\n$$ \\begin{equation} \\text{snorm}(x) = \\sqrt{x^2 + \\epsilon^2} - \\epsilon \\end{equation} $$\n$$ \\begin{equation} || f_x || \\approx \\text{snorm}(f_x) \\end{equation} $$\nThe optimization problem is as follows.\n$$ \\begin{align} \\min_{X_{k\u0026#43;1}, f_z, f_x, s_1, s_2} \\quad \u0026amp; s_1^2 \u0026#43; s_2^2 \\\\ \\textrm{s.t.} \\quad \u0026amp; A_dX_k \u0026#43; B_dF_k \u0026#43; G_d - X_{k\u0026#43;1} = 0 \\\\ \u0026amp; s_1 - f_z z_{k\u0026#43;1} \\geq 0 \\\\ \u0026amp; z_{k\u0026#43;1} \\geq 0 \\\\ \u0026amp; f_z \\geq 0 \\\\ \u0026amp; s_1 \\geq 0 \\\\ \u0026amp; \\dot{x}_k \u0026#43; \\lambda_k \\frac{f_x}{\\text{snorm}(f_x) \u0026#43; \\epsilon} = 0 \\\\ \u0026amp; \\mu f_z - \\text{snorm}(f_x) \\geq 0 \\\\ \u0026amp; s_2 - \\lambda_k (\\mu f_z - \\text{snorm}(f_x)) \\geq 0 \\\\ \u0026amp; s_2 \\geq 0 \\\\ \u0026amp; \\lambda_k \\geq 0 \\end{align} $$ An explanation of what\u0026rsquo;s going on here:\nEqs. (10) through (14) are the contact constraints we covered in the last post. The original slack variable is now denoted as $s_1$. Eq. (15) is Eq. (5), but smoothed, plus an additional $\\epsilon$ to prevent division by zero. Eq. (16) is Eq. (3) smoothed. Eq. (17) is Eq. (4) with a second slack variable, $s_2$. Note that I am using $f_x$ and $f_z$ to refer to the elements of the force vector at timestep $k$ to avoid complicating the notation.\n$$ \\begin{equation} F_k = \\begin{bmatrix} f_x \\\\ f_z \\end{bmatrix} \\end{equation} $$ Furthermore, assume that any slack variables mentioned ($s_1$ and $s_2$) are also taken at timestep $k$.\nNow that that\u0026rsquo;s out of the way, let\u0026rsquo;s look at the code.\nThe Code We start out by defining the \u0026ldquo;smooth norm\u0026rdquo; function, the solver tolerance, the 2D dynamics, and the integrator.\nimport numpy as np import casadi as cs import plotting ϵ = 1e-4 def smoothnorm(x): return cs.sqrt(x**2 + ϵ * ϵ) - ϵ n_a = 4 # length of state vector n_u = 2 # length of control vector m = 10 # mass of the particle in kg g = 9.81 # gravitational constant A = np.array([[0, 0, 1, 0], [0, 0, 0, 1], [0, 0, 0, 0], [0, 0, 0, 0]]) B = np.array([[0, 0], [0, 0], [1 / m, 0], [0, 1 / m]]) G = np.array([[0, 0, 0, -g]]).T dt = 0.001 # timestep size mu = 0.1 # coefficient of friction def dynamics_ct(X, U): dX = A @ X + B @ U + G.flatten() return dX def integrator_euler_semi_implicit(dyn_ct, xk, uk, xk1): xk_semi = cs.SX.zeros(n_a) xk_semi[:2] = xk[:2] xk_semi[2:] = xk1[2:] X_next = xk + dt * dyn_ct(xk_semi, uk) return X_next Next, we set up the solver.\nN = 1200 # number of timesteps X_hist = np.zeros((N, n_a)) # array of state vectors for each timestep Fx_hist = np.zeros(N) # array of x friction forces for each timestep Fz_hist = np.zeros(N) # array of z GRF forces for each timestep X_hist[0, :] = np.array([[0, 1, 1, 0]]) U_hist = np.zeros((N - 1, n_u)) # array of control vectors for each timestep # initialize casadi variables Xk1 = cs.SX.sym(\u0026#34;Xk1\u0026#34;, n_a) # X(k+1), state at next timestep F = cs.SX.sym(\u0026#34;F\u0026#34;, n_u) # forces s1 = cs.SX.sym(\u0026#34;s1\u0026#34;, 1) # slack variable 1 s2 = cs.SX.sym(\u0026#34;s2\u0026#34;, 1) # slack variable 2 lam = cs.SX.sym(\u0026#34;lam\u0026#34;, 1) # lagrange mult for ground vel X = cs.SX.sym(\u0026#34;X\u0026#34;, n_a) # state U = cs.SX.sym(\u0026#34;U\u0026#34;, n_u) # controls xk = X[0] zk = X[1] dxk = X[2] Fx = F[0] # friction force Fz = F[1] # grf xk1 = Xk1[0] # horz pos zk1 = Xk1[1] # vert pos # objective function obj = s1**2 + s2**2 constr = [] # init constraints # dynamics constr = cs.vertcat( constr, cs.SX(integrator_euler_semi_implicit(dynamics_ct, X, U + F, Xk1) - Xk1) ) # tang. gnd vel is zero if GRF is zero but is otherwise equal to dx # max dissipation constr = cs.vertcat(constr, cs.SX(dxk + lam * Fx / (smoothnorm(Fx) + ϵ))) # primal feasibility primal_friction = mu * Fz - smoothnorm(Fx) # uN = Ff constr = cs.vertcat(constr, cs.SX(primal_friction)) # friction cone # relaxed complementarity aka compl. slackness constr = cs.vertcat(constr, cs.SX(s1 - Fz * zk1)) # ground penetration constr = cs.vertcat(constr, cs.SX(s2 - lam * primal_friction)) # friction opt_variables = cs.vertcat(Xk1, F, s1, s2, lam) parameters = cs.vertcat(X, U) lcp = {\u0026#34;x\u0026#34;: opt_variables, \u0026#34;p\u0026#34;: parameters, \u0026#34;f\u0026#34;: obj, \u0026#34;g\u0026#34;: constr} opts = { \u0026#34;print_time\u0026#34;: 0, \u0026#34;ipopt.print_level\u0026#34;: 0, \u0026#34;ipopt.tol\u0026#34;: ϵ, \u0026#34;ipopt.max_iter\u0026#34;: 2000, } solver = cs.nlpsol(\u0026#34;S\u0026#34;, \u0026#34;ipopt\u0026#34;, lcp, opts) Then we define our constraint bounds.\nn_var = np.shape(opt_variables)[0] n_par = np.shape(parameters)[0] n_g = np.shape(constr)[0] # variable bounds ubx = [1e10] * n_var lbx = [0] * n_var # dual feasibility lbx[0] = -1e10 # set x unlimited lbx[2] = -1e10 # set dx unlimited lbx[3] = -1e10 # set dz unlimited lbx[n_a] = -1e10 # set Fx unlimited # constraint bounds ubg = [1e10] * n_g ubg[0:n_a] = np.zeros(n_a) # set dynamics = 0 ubg[n_a] = 0 # set max dissipation = 0 lbg = [0] * n_g Finally, we step through the simulation.\n# run the sim p_values = np.zeros(n_par) x0_values = np.zeros(n_var) s1_hist = np.zeros(N) s2_hist = np.zeros(N) lam_hist = np.zeros(N) for k in range(N - 1): print(\u0026#34;timestep = \u0026#34;, k) p_values[:n_a] = X_hist[k, :] p_values[n_a:] = U_hist[k, :] x0_values[:n_a] = X_hist[k, :] sol = solver(lbx=lbx, ubx=ubx, lbg=lbg, ubg=ubg, p=p_values, x0=x0_values) X_hist[k + 1, :] = np.reshape(sol[\u0026#34;x\u0026#34;][0:n_a], (-1,)) Fx_hist[k] = sol[\u0026#34;x\u0026#34;][n_a] Fz_hist[k] = sol[\u0026#34;x\u0026#34;][n_a + 1] s1_hist[k] = sol[\u0026#34;x\u0026#34;][n_a + 2] s2_hist[k] = sol[\u0026#34;x\u0026#34;][n_a + 3] lam_hist[k] = sol[\u0026#34;x\u0026#34;][n_a + 4] x_hist = X_hist[:, 0] z_hist = X_hist[:, 1] dx_hist = X_hist[:, 2] dz_hist = X_hist[:, 3] Click here for the full code.\nHere\u0026rsquo;s the result.\nNeat! Although the plot looks a little messy\u0026ndash;again, IPOPT is not really the right solver for this.\nA Note on Friction with Hybrid and Smooth Contact With the smooth and hybrid contact models, friction is simple enough that I\u0026rsquo;m not going to cover them here. I\u0026rsquo;m just going to provide example code below.\n2D Hybrid Contact + Friction\n2D Smooth Contact + Friction\nAppendix If you want to learn more about this stuff, check out these sources.\n16-715: Simulating Coulomb Friction\nSIGGRAPH'22 Course: Contact and Friction Simulation for Computer Graphics\n","permalink":"https://bbokser.github.io/posts/2025-01-20/","summary":"\u003cp\u003eIn this post, we will add 1-dimensional coulomb friction to our simulation.\u003c/p\u003e\n\u003cp\u003eFirst off, we\u0026rsquo;re going to need to allow movement in the horizontal direction.\nOur new state-space system will be a 2-dimensional system subject to both horizontal and vertical forces.\u003c/p\u003e\n \n$$\n\\begin{equation}\n\\underbrace{\\begin{bmatrix} \\dot{x} \\\\ \\dot{z} \\\\ \\ddot{x} \\\\ \\ddot{z} \\end{bmatrix}}_{\\dot{X}} = \n\\underbrace{\\begin{bmatrix}\n\t0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\\\\n    0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\\\\n    0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\\n    0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\\n\\end{bmatrix}}_A\n\\underbrace{\\begin{bmatrix}\n    x \\\\\n    z \\\\\n    \\dot{x} \\\\ \n    \\dot{z} \n\\end{bmatrix}}_X \n\u0026#43; \\underbrace{\\begin{bmatrix} \n    0 \u0026amp; 0 \\\\\n    0 \u0026amp; 0 \\\\ \n    \\frac{1}{m} \u0026amp; 0 \\\\\n    0 \u0026amp; \\frac{1}{m}\n\\end{bmatrix}}_B \n\\underbrace{\\begin{bmatrix}\n    f_x \\\\\n    f_z\n\\end{bmatrix}}_F \n\u0026#43; \\underbrace{\\begin{bmatrix} \n    0 \\\\\n    0 \\\\\n    0 \\\\\n    -9.81 \n\\end{bmatrix}}_G\n\\end{equation}\n$$\n\u003ch2 id=\"modeling-friction\"\u003eModeling Friction\u003c/h2\u003e\n\u003cp\u003eFor 1-dimensional Coulomb friction, our friction force, $f_x$, is related to our vertical force $f_z$ by the following equation.\u003c/p\u003e","title":"Intro to Robot Simulation, Part 3: Friction"},{"content":"Okay, so we can simulate a floating point mass subject to arbitrary forces. Let\u0026rsquo;s now think about what happens when our point mass hits the ground.\nAssuming 100% stiff, inelastic impact, we would get the following position, velocity, and acceleration trajectories:\nNotably, the acceleration at impact approaches infinity, which would be very difficult to simulate\u0026ndash;it would require infinitesimal timesteps. Of course, in reality there is no such thing as a perfectly stiff and inelastic collision, but in the field of robotics we are often concerned with relatively stiff collisions which cause decelerations on the order of microseconds.\nSo how do we do that?\nGeneralizing grossly, there are three overarching categories of methods for simulating contact, which I will cover here.\nThe Hybrid Method In this method, a \u0026ldquo;guard function\u0026rdquo; explicitly checks for contact on every timestep. If it is triggered, a \u0026ldquo;jump map\u0026rdquo; function is called, which applies impact discontinuities. Additionally, separate dynamics models can be used depending on whether or not the object is currently in contact.\nLet\u0026rsquo;s look at a code example. We will use the same state-space system from Part 1, a vertically constrained point mass.\nimport numpy as np import plotting n_x = 2 # length of state vector n_u = 1 # length of control vector m = 10 # mass of the rocket in kg A = np.array([[0, 1], [0, 0]]) B = np.array([[0], [1 / m]]) G = np.array([[0], [-9.81]]) dt = 0.001 # timestep size def dynamics_ct(X, U): dX = A @ X + B @ U + G.flatten() return dX def integrator_euler(dyn_ct, xk, uk): X_next = xk + dt * dyn_ct(xk, uk) return X_next Next, we define our \u0026ldquo;jump map\u0026rdquo;. This function will be called whenever the object passes through the ground. It rewrites the position to avoid interpenetration. In addition, it rewrites the velocity based on a chosen coefficient of restitution $e$ and calculates the ground reaction force necessary for this to occur. Here we have set $e$ to 0.7 arbitrarily.\ne = 0.7 # coefficient of restitution def jump_map(X): # X[0] = 0 # reset z position to zero v_before = X[1] # velocity before impact v_after = ( -e * v_before ) # reverse velocity and multiply by coefficient of restitution a = (v_after - v_before) / dt # acceleration F = m * a # get ground reaction force X[1] = v_after # velocity after impact return X, F Finally, we iterate through the timesteps. The jump map is called whenever the object\u0026rsquo;s position value is negative.\nN = 1000 # number of timesteps X_hist = np.zeros((N, n_x)) # array of state vectors for each timestep F_hist = np.zeros((N, 1)) # array of state vectors for each timestep X_hist[0, :] = np.array([[1, 0]]) # start from a height of 1 m U_hist = np.zeros((N - 1, n_u)) # array of control vectors for each timestep for k in range(N - 1): if X_hist[k, 0] \u0026lt;= 0: # guard function X_hist[k, :], F_hist[k, :] = jump_map( X_hist[k, :] ) # dynamics rewrite based on impact X_hist[k + 1, :] = integrator_euler(dynamics_ct, X_hist[k, :], U_hist[k, :]) Click here for the full code.\nLet\u0026rsquo;s look at the results: Everything here seems reasonable, except that the ball is probably unrealistically stiff for how bouncy it is.\nAlso, set $e = 0$ to see what an inelastic collision looks like:\nNeat!\nSmooth Contact In this method, contact is approximated as a spring-damper system. The trick here is that the spring-damper model is used at all times, regardless of whether or not contact should be occurring.\nLet\u0026rsquo;s look at the code.\nThe function below takes as inputs the distance of the object from the ground and its speed. It then calculates the ground reaction force based on user-tuned spring and damping constants.\ndef get_grf(X: np.ndarray) -\u0026gt; float: z = X[0] dz = X[1] k = 0.01 # spring constant b = 0.1 # damping constant amp = 1500 # desired max force c = amp * 0.5 / k distance_fn = -c * np.tanh(z * 100) + c F_spring = k * distance_fn F_damper = -b * dz * distance_fn grf = F_spring + F_damper return grf If we plot this function, we see that the force drops off precipitously as distance from the ground increases.\nI chose a $\\tanh$ relationship between input and output somewhat arbitrarily to achieve this effect. As a consequence there is a max ground reaction force possible, which isn\u0026rsquo;t great. But you can tune it.\nLet\u0026rsquo;s look at the rest of the code now. The dynamics and integrator are exactly the same as in the hybrid example.\nBut the simulation is simpler. There\u0026rsquo;s no explicit check for interpenetration; the spring-damper function is simply called on every timestep. When the object isn\u0026rsquo;t close to the ground, the forces are just too small to notice. This is what makes the smooth contact method both beautifully elegant, and just wrong.\nn_x = 2 # length of state vector n_u = 1 # length of control vector m = 10 # mass of the rocket in kg A = np.array([[0, 1], [0, 0]]) B = np.array([[0], [1 / m]]) G = np.array([[0], [-9.81]]) dt = 0.001 # timestep size def dynamics_ct(X, U): dX = A @ X + B @ U + G.flatten() return dX def integrator_euler(dyn_ct, xk, uk): X_next = xk + dt * dyn_ct(xk, uk) return X_next N = 1000 # number of timesteps X_hist = np.zeros((N, n_x)) # array of state vectors for each timestep F_hist = np.zeros((N, n_u)) # array of state vectors for each timestep X_hist[0, :] = np.array([[1, 0]]) for k in range(N - 1): F_hist[k, :] = get_grf(X_hist[k, :]) # get spring-damper force X_hist[k + 1, :] = integrator_euler(dynamics_ct, X_hist[k, :], F_hist[k, :]) Click here for the full code.\nNote that I\u0026rsquo;m feeding the ground reaction force in to where the control vector is supposed to go. Since both the control and GRF can apply a vertical force, this is a little cheat to let me write less lines of code.\nLet\u0026rsquo;s look at the results. Pretty good!\nTime-Stepping In this method, an optimization problem is solved on each timestep to compute the contact forces required to satisfy interpenetration constraints.\nIdeally, the system is described by the following four constraints. The first is our discrete-time system dynamics. Here, $X_k$ and $U_k$ are inputs and we want to solve for $X_{k+1}$ and $f_k$, where $f_k$ represents the reaction force between the ground and the point mass. Out of a convenient contrivance, $f_k$ uses the same input matrix $B_d$ as the control input $U_k$.\n$$ \\begin{equation} X_{k+1} = A_dX_k + B_dU_k + B_df_k + G_d \\end{equation} $$\nSecondly, we have our interpenetration constraint. This just says that the point mass must stay above the ground. As a reminder, $z_{k+1}$ is an element of $X_{k+1}$. $$ \\begin{equation} z_{k+1} \\geq 0 \\end{equation} $$\nThirdly, we constrain the ground reaction force to be positive only. If it were negative, the ground would be pulling on the mass.\n$$ \\begin{equation} f_k \\geq 0 \\end{equation} $$\nAnd finally, we have what is known as the complementarity constraint. This is a pretty neat trick. In order for the constraint to be satisfied, either $f_k$ or $z_{k+1}$ must be equal to zero at any given timestep. Therefore, when the object is not touching the ground, $f_k$ must be zero.\n$$ \\begin{equation} f_k z_{k+1} = 0 \\end{equation} $$\nThe Optimization Problem To practically implement this in an easy and accessible way, we will be using the IPOPT solver, which is broadly available. Bear in mind that you really need to write a custom solver to do this properly. But to make this solvable with IPOPT, we have to add a slack variable, denoted by $s$, to \u0026ldquo;relax\u0026rdquo; the discrete switching behavior of the complementarity constraint.\nThe optimization problem is as shown below. We attempt to minimize $s^2$ in the objective function, as opposed to just $s$, because it penalizes larger values more severely.\n$$ \\begin{align} \\min_{X_{k\u0026#43;1}, f_k, s_k} \\quad \u0026amp; s_k^2 \\\\ \\textrm{s.t.} \\quad \u0026amp; A_dX_k \u0026#43; B_dU_k \u0026#43; B_df_k \u0026#43; G_d - X_{k\u0026#43;1} = 0 \\\\ \u0026amp; s_k - f_k z_{k\u0026#43;1} \\geq 0 \\\\ \u0026amp; z_{k\u0026#43;1} \\geq 0 \\\\ \u0026amp; f_k \\geq 0 \\\\ \u0026amp; s_k \\geq 0 \\\\ \\end{align} $$ The Code Starting with standard setup stuff, except that we are going to use the semi-implicit Euler method, which performs better here than other integrators. The only difference between it and the regular Euler method is that it uses the velocity term from the next ($k+1$) timestep.\nimport numpy as np import plotting import casadi as cs n_a = 2 # length of state vector n_u = 1 # length of control vector m = 10 # mass of the particle in kg g = 9.81 # gravitational constant A = np.array([[0, 1], [0, 0]]) B = np.array([[0], [1 / m]]) G = np.array([[0], [-g]]) dt = 0.001 # timestep size def dynamics_ct(X, U): dX = A @ X + B @ U + G.flatten() return dX def integrator_euler_semi_implicit(dyn_ct, xk, uk, xk1): xk_semi = cs.SX.zeros(n_a) xk_semi[0] = xk[0] xk_semi[1] = xk1[1] X_next = xk + dt * dyn_ct(xk_semi, uk) return X_next X_0 = np.array([1, 0]) N = 1000 X_hist = np.zeros((N, n_a)) # array of state vectors for each timestep F_hist = np.zeros(N) # array of z GRF forces for each timestep s_hist = np.zeros(N) # array of slack var values for each timestep X_hist[0, :] = X_0 U_hist = np.zeros((N - 1, n_u)) # array of control vectors for each timestep Here is where we define the optimization problem. We are using CaSaDi, a library for numerical optimization that has IPOPT built-in.\n# initialize casadi variables Xk1 = cs.SX.sym(\u0026#34;Xk1\u0026#34;, n_a) # X(k+1), state at next timestep F = cs.SX.sym(\u0026#34;F\u0026#34;, n_u) # force s = cs.SX.sym(\u0026#34;s\u0026#34;, 1) # slack variable X = cs.SX.sym(\u0026#34;X\u0026#34;, n_a) # state U = cs.SX.sym(\u0026#34;U\u0026#34;, n_u) # controls zk1 = Xk1[0] # vert pos dzk1 = Xk1[1] # vertical vel obj = s**2 constr = [] # init constraints # dynamics constr = cs.vertcat( constr, cs.SX(integrator_euler_semi_implicit(dynamics_ct, X, U + F, Xk1) - Xk1) ) # relaxed complementarity constr = cs.vertcat(constr, cs.SX(s - F * zk1)) opt_variables = cs.vertcat(Xk1, F, s) # parameters = X parameters = cs.vertcat(X, U) lcp = {\u0026#34;x\u0026#34;: opt_variables, \u0026#34;p\u0026#34;: parameters, \u0026#34;f\u0026#34;: obj, \u0026#34;g\u0026#34;: constr} opts = { \u0026#34;print_time\u0026#34;: 0, \u0026#34;ipopt.print_level\u0026#34;: 0, \u0026#34;ipopt.tol\u0026#34;: 1e-6, \u0026#34;ipopt.max_iter\u0026#34;: 500, } solver = cs.nlpsol(\u0026#34;S\u0026#34;, \u0026#34;ipopt\u0026#34;, lcp, opts) You may have noticed that constraints (8), (9), and (10) aren\u0026rsquo;t shown above. That\u0026rsquo;s because they can be defined as variable bounds:\nn_var = np.shape(opt_variables)[0] n_par = np.shape(parameters)[0] n_g = np.shape(constr)[0] # variable bounds ubx = [1e10] * n_var lbx = [-1e10] * n_var lbx[0] = 0 # set z positive only lbx[n_a] = 0 # set F positive only lbx[-1] = 0 # set slack variable \u0026gt;= 0 Next we define the numerical values of the constraint bounds.\n# constraint bounds ubg = [0] * n_g ubg[-1] = 1e10 # set relaxed complementarity \u0026gt;= 0 lbg = [0] * n_g And finally, we run the sim. As previously noted, $X_k$ and $U_k$ are input parameters to the solver and the value of $X_k$ is taken from the previous timestep.\n# run the sim p_values = np.zeros(n_par) x0_values = np.zeros(n_var) for k in range(N - 1): print(\u0026#34;timestep = \u0026#34;, k) p_values[:n_a] = X_hist[k, :] p_values[n_a:] = U_hist[k, :] x0_values[:n_a] = X_hist[k, :] sol = solver(lbx=lbx, ubx=ubx, lbg=lbg, ubg=ubg, p=p_values, x0=x0_values) X_hist[k + 1, :] = np.reshape(sol[\u0026#34;x\u0026#34;][0:n_a], (-1,)) F_hist[k] = sol[\u0026#34;x\u0026#34;][n_a] s_hist[k] = sol[\u0026#34;x\u0026#34;][n_a + n_u] pos_hist = X_hist[:, 0] vel_hist = X_hist[:, 1] Click here for the full code.\nHere\u0026rsquo;s the result.\nConclusion Here\u0026rsquo;s a comparison of the three presented methods.\nMethod Pros Cons Hybrid Accurate Does not scale well with increasing points of contact, difficulty with simultaneous impacts, not differentiable Smooth Simple, multiple and simultaneous contact, differentiable Low accuracy Time-Stepping Accurate, multiple and simultaneous contact Difficult implementation, very computationally expensive, not differentiable In the next post in this series, I\u0026rsquo;ll add friction into the mix, so stay tuned. Also, check out Zac Manchester\u0026rsquo;s class on robot dynamics, which I ripped off pretty heavily for this post.\n","permalink":"https://bbokser.github.io/posts/2024-12-31/","summary":"\u003cp\u003eOkay, so we can simulate a floating point mass subject to arbitrary forces.\nLet\u0026rsquo;s now think about what happens when our point mass hits the ground.\u003c/p\u003e\n\u003cp\u003eAssuming 100% stiff, inelastic impact, we would get the following position, velocity, and acceleration trajectories:\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2024-12-31/impact.png\"\u003e\u003c/p\u003e\n\u003cp\u003eNotably, the acceleration at impact approaches infinity, which would be very difficult to simulate\u0026ndash;it would require infinitesimal timesteps.\nOf course, in reality there is no such thing as a perfectly stiff and inelastic collision,\nbut in the field of robotics we are often concerned with relatively stiff collisions which cause decelerations on the order of microseconds.\u003c/p\u003e","title":"Intro to Robot Simulation, Part 2: Contact"},{"content":"I love little semi-retro gadgets, maybe because I grew up playing a GameBoy? Anyway, a few months ago, this video about Rockbox really sold me on getting a first-generation Sandisk Sansa Clip, and I ended up ordering an unopened one off Ebay.\nThere was one problem, though. Turns out if you leave a LiPo pack on the shelf for ~15-17 years it stops working. And the Sansa Clip was never designed to be repairable.\nFirst, I had to jimmy the cover open without damaging the little guy, which turned out to be very tedious and frustrating. It was all uphill from there though.\nNext, I had to solder a new battery in. This isn\u0026rsquo;t the original battery model, by the way\u0026ndash;the original was Sandisk-specific. This is just a roughly equivalent generic battery.\nAnd it turned out the new battery\u0026rsquo;s leads were too short, and soldering directly to the ends of the leads led to such large solder joints that I could no longer fit the battery in the case. So I ended up desoldering the original leads and soldering my own wires between the battery and the Sansa Clip, which involved removing the kapton tape and unfolding the tiny pcb attached to the battery.\nThis was admittedly a little nerve-wracking, but I tried my best not to skewer the battery with my soldering iron, and everything turned out great.\nEven after all that effort, it turned out the new battery still wouldn\u0026rsquo;t fit in the old back cover\u0026ndash;it\u0026rsquo;s just not shaped quite the same. The old back cover was pretty dinged up from being forced open anyway, and it wouldn\u0026rsquo;t have gone back together securely. So I ended up designing a new case. In retrospect, I should have just given the new case a bit more depth so that I wouldn\u0026rsquo;t have had to rework the wires, but oh well.\nThe new case envelops the original front cover and replaces the original back cover. I didn\u0026rsquo;t include the clip attachment because I didn\u0026rsquo;t feel I needed it.\nContinuing with the nostalgia junkie theme, the clear craze felt fitting here\u0026ndash;and hey, I went through all that effort to replace the battery, so why not show it? So I printed the case out of Formlabs Clear V4 resin, even though Clear is brittle and would likely shatter if dropped.\nAnyway, I\u0026rsquo;m quite pleased with the result. Could\u0026rsquo;ve polished the case a bit more, but oh well.\nHere\u0026rsquo;s the CAD if you want.\n","permalink":"https://bbokser.github.io/posts/2024-06-12/","summary":"\u003cp\u003eI love little semi-retro gadgets, maybe because I grew up playing a GameBoy? Anyway, a few months ago, \u003ca href=\"https://youtu.be/Qw-VvGsYpSU?feature=shared\"\u003ethis video about Rockbox\u003c/a\u003e really sold me on getting a first-generation Sandisk Sansa Clip, and I ended up ordering an unopened one off Ebay.\u003c/p\u003e\n\u003cp\u003eThere was one problem, though. Turns out if you leave a LiPo pack on the shelf for ~15-17 years it stops working. And the Sansa Clip was never designed to be repairable.\u003c/p\u003e","title":"Reviving an MP3 Player from 2007"},{"content":"So, you want to write your own dynamic robot simulation from scratch.\nLet\u0026rsquo;s start with one of the simplest possible dynamical systems: a vertically constrained point mass. Think of it as a rocket locked to a linear rail.\nThe rocket cannot rotate or translate laterally; it can only move up or down, and can it only control this by either exerting an upward force or letting gravity take its course.\nTherefore, we can solve for the acceleration of the rocket as follows:\n$$ \\begin{equation} \\ddot{z} = \\frac{u}{m} - 9.81 \\end{equation} $$\nWhere $\\ddot{z}$ is the rocket\u0026rsquo;s vertical acceleration, $u$ is the force exerted by the rocket, $m$ is the rocket\u0026rsquo;s mass, and the additional term is gravity.\nWriting a CT State Space Model We begin by rewriting Eq(1) as a continuous-time (CT) linear state space representation of the system. Our state vector, usually denoted by $X$, is composed of the vertical position $z$ and its vertical velocity $\\dot{z}$.\n$$ \\begin{equation} X = \\begin{bmatrix} z \\\\ \\dot{z} \\end{bmatrix} \\end{equation} $$ The purpose of the CT state-space representation is to solve for the derivative of $X$:\n$$ \\begin{equation} \\dot{X} = \\begin{bmatrix} \\dot{z} \\\\ \\ddot{z} \\end{bmatrix} \\end{equation} $$ For the rocket-on-a-rail, this can be solved as such:\n$$ \\begin{equation} \\underbrace{\\begin{bmatrix} \\dot{z} \\\\ \\ddot{z} \\end{bmatrix}}_{\\dot{X}} = \\underbrace{\\begin{bmatrix} 0 \u0026amp; 1 \\\\ 0 \u0026amp; 0 \\end{bmatrix}}_A \\underbrace{\\begin{bmatrix} z \\\\ \\dot{z} \\end{bmatrix}}_X \u0026#43; \\underbrace{\\begin{bmatrix} 0 \\\\ \\frac{1}{m} \\end{bmatrix}}_B u \u0026#43; \\underbrace{\\begin{bmatrix} 0 \\\\ -9.81 \\end{bmatrix}}_G \\end{equation} $$ Note the $A$ matrix (AKA \u0026ldquo;the state matrix\u0026rdquo;), which governs how $X$ affects $\\dot{X}$. In this case, the only relation is that $\\dot{z} = \\dot{z}$.\nSecondly, the B matrix (AKA \u0026ldquo;the input matrix\u0026rdquo;) governs how the control input $U$ affects $\\dot{X}.$\nFinally, the G matrix represents a disturbance, which in this case is the constant acceleration acting on the system due to gravity.\nFrom Continuous-Time to Discrete-Time Continuous-time state space models represent the dynamics of a system with respect to time. Let\u0026rsquo;s focus on the linear time-invariant (LTI) case to keep things simple (This means that the A and B matrices are not functions of time, e.g. $A(t)$).\n$$ \\begin{equation} \\dot{X}(t) = A X(t) + B U(t) \\end{equation} $$\nNow imagine if we wanted to simulate such a system. We would need to measure the state $X(t)$ for various values of $t$. This would not be possible, as we are only solving for its derivative, $\\dot{X}(t)$!\nLuckily, there is a solution for the LTI case that makes this possible:\n$$ \\begin{equation} X(t) = e^{(t - t_0)A} X(t_0) + \\int^t_{t_0} e^{A (t-\\tau)} B u(\\tau) d\\tau \\end{equation} $$\nThe problem, of course, is that it requires the calculation of a matrix exponential, $e^A$, the solution for which is an infinite series.\nThe main takeaway here is that any attempt to simulate a LTI state space system can be interpreted as an approximation of the matrix exponential. There are many ways to do this (at least nineteen!), but I will only cover a few here.\nOkay, anyway, we can solve for $X(t)$ now. But do we want to find $X$ for any arbitrary $t$? Actually, it is most convenient to \u0026ldquo;step\u0026rdquo; through time at a constant rate. The time between each step is known as a timestep and will be written as $dt$ here.\nWith this in mind, we should now be concerned with discrete timesteps $k$, and as such we rewrite the model in discretized form as follows: $$ \\begin{equation} X_{k+1} = A_d X_k + B_d U_k + G_d \\end{equation} $$\nNote that instead of calculating $\\dot{X}$, we are now attempting to calculate $X_{k+1}$, which is just $X$ at the next timestep.\nThe expm() Method The most obvious way to solve for the state at each timestep is to simply call a function that solves the matrix exponential. In this case, we use scipy.linalg.expm(). This also happens to be one the most accurate methods (although it\u0026rsquo;s still technically an approximation), and one of the most computationally expensive.\nThe code in this guide is written in Python. We will start by importing necessary libraries and defining the constants.\nimport numpy as np from scipy.linalg import expm import matplotlib.pyplot as plt n_x = 2 # length of state vector n_u = 1 # length of control vector m = 10 # mass of the rocket in kg A = np.array([[0, 1], [0, 0]]) B = np.array([[0], [1/m]]) G = np.array([[0], [-9.81]]) dt = 0.001 # timestep size Next, we calculate the discretized dynamics using expm(). Because expm() only accepts square matrices, and $B$ and $G$ are not square, we perform a little trick here where we merge $A$, $B$, and $G$ into one big square matrix using a few extra rows of zeros. Then we extract the discretized $A_d$, $B_d$, and $G_d$ from the result.\nABG = np.vstack((np.hstack((A, B, G)), np.zeros((n_u + 1, n_x + n_u + 1)))) M = expm(ABG * dt) Ad = M[0:n_x, 0:n_x] Bd = M[0:n_x, n_x:n_x + n_u] Gd = M[0:n_x, n_x + n_u:] def dynamics_dt(X, U): X_next = Ad @ X + Bd @ U + Gd.flatten() return X_next Now we can set the simulation up, run it, and plot the result.\nN = 1000 # number of timesteps X_hist = np.zeros((N, n_x)) # array of state vectors for each timestep X_hist[0, :] = np.array([[1, 0]]) U_hist = np.zeros((N-1, n_u)) # array of control vectors for each timestep for k in range(N-1): X_hist[k+1, :] = dynamics_dt(X_hist[k, :], U_hist[k, :]) plt.plot(range(N), X_hist[:, 0], label=\u0026#39;expm\u0026#39;) plt.title(\u0026#39;Body Position vs Time\u0026#39;) plt.ylabel(\u0026#34;z (m)\u0026#34;) plt.xlabel(\u0026#34;timesteps\u0026#34;) plt.show() The full code can be found here. You should get the following result:\nAs you can see, the point mass accelerates downward due to gravity. Simple stuff.\nThe Explicit Euler Method There is a broad class of methods known as Runge-Kutta, which can be used to discretize any transient problem, including nonlinear ones. The explicit Euler method (AKA foward Euler method) is probably the simplest of those, which is why I am covering it here. Unlike the previous discretization method, it is extremely computationally efficient, albeit inaccurate and unstable. The explicit Euler method is the standard discretization method used in video games, where physical accuracy is considered \u0026ldquo;optional\u0026rdquo;.\nLike I said, the explicit Euler method is simple. It assumes that the state at the next timestep is simply the current state plus the state derivative multiplied by the timestep size. This makes a lot of intuitive sense.\n$$ \\begin{equation} X_{k+1} = X_k + \\dot{X_k}\\text{dt} \\end{equation} $$\nLet\u0026rsquo;s see how this looks in code:\ndef dynamics_ct(X, U): dX = A @ X + B @ U + G.flatten() return dX def integrator_euler(dyn_ct, xk, uk): X_next = xk + dt * dyn_ct(xk, uk) return X_next Now, replace the for loop from earlier with the following:\nfor k in range(N-1): X_hist[k+1, :] = integrator_euler(dynamics_ct, X_hist[k, :], U_hist[k, :]) Your resulting plot should look exactly the same.\nThe Fourth-Order Runge-Kutta Method Despite its computational efficiency, the explicit Euler method is not ideal for robotics. Higher-order Runge-Kutta methods are generally preferred due to their superior accuracy and stability. The fourth-order Runge-Kutta method (RK4) is one of the most popular.\nFor brevity, I won\u0026rsquo;t explain how/why it works here, but you can try it out by replacing the integrator_euler() function with the following:\ndef integrator_rk4(dyn_ct, xk, uk): f1 = dyn_ct(xk, uk) f2 = dyn_ct(xk + 0.5 * dt * f1, uk) f3 = dyn_ct(xk + 0.5 * dt * f2, uk) f4 = dyn_ct(xk + dt * f3, uk) return xk + (dt / 6.0) * (f1 + 2 * f2 + 2 * f3 + f4) For such a simple setup, you won\u0026rsquo;t notice much of a difference between these methods until you turn the timestep size way up. The following plot compares all three methods covered here using a timestep size of a tenth of a second.\nThe expm result should be taken as \u0026ldquo;ground truth\u0026rdquo;. As you can see, the explicit Euler method visibly diverges from \u0026ldquo;truth\u0026rdquo;, but it is still not possible to distinguish the RK4 results from expm.\nAdding Control One more thing. After the first half a second, let\u0026rsquo;s add a 1000N force to the control vector applied over the course of a quarter second and see what happens.\nN = 5000 # number of timesteps X_hist = np.zeros((N, n_x)) # array of state vectors for each timestep X_hist[0, :] = np.array([[1, 0]]) U_hist = np.zeros((N-1, n_u)) # array of control vectors for each timestep U_hist[500:750, :] = 1000 # HERE! for k in range(N-1): X_hist[k+1, :] = dynamics_dt(X_hist[k, :], U_hist[k, :]) Whee!\nNext Steps In the next part of this series, I will cover how contact is simulated, so that the point mass can bounce off the ground.\n","permalink":"https://bbokser.github.io/posts/2024-02-18/","summary":"\u003cp\u003eSo, you want to write your own dynamic robot simulation from scratch.\u003c/p\u003e\n\u003cp\u003eLet\u0026rsquo;s start with one of the simplest possible dynamical systems: a vertically constrained point mass.\nThink of it as a rocket locked to a linear rail.\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2024-02-18/rocket.png\"\u003e\u003c/p\u003e\n\u003cp\u003eThe rocket cannot rotate or translate laterally; it can only move up or down,\nand can it only control this by either exerting an upward force or letting gravity take its course.\u003c/p\u003e","title":"Intro to Robot Simulation, Part 1: Point Masses"},{"content":"The Problem Let\u0026rsquo;s say we need to design a structural section of a robot arm, as shown.\nWe\u0026rsquo;ve been given a few requirements:\nThe mass of the component must be minimized at all costs. The length of the link must be 300 mm. The maximum allowed deflection (caused by the component) is 1 mm. The combined mass of the maximum payload and end-effector is 30 kg. The combined center of mass of the payload and end-effector is 50 mm from the joint. Both the base and end-effector joints can rotate in any axis. We are allowed to assume that the arm does not move dynamically, so that our analysis can be static-only.\nSo how do we optimally design this component?\nAbstraction Let\u0026rsquo;s start by simplifying the situation by only looking at the worst-case scenario, as shown. In this case, maximum bending moment will be acting along the length of the arm and maximum torsion will be acting on it in the axial direction.\nLet\u0026rsquo;s redraw it as a cantilever beam.\nRemember what we know from the requirements:\n$L_x = 300 \\text{ mm}$ $L_y = 50 \\text{ mm}$ $m = 30 \\text{ kg}$ Choice of Cross-Section Choosing the cross-sectional shape of a cantilever beam is all about maximizing your second moment of area, a major determining factor in both stiffness and strength. On the other hand, you\u0026rsquo;ll also want to minimize cross-sectional area to ensure that the mass of the beam is as low as possible.\nHow do we maximize second moment of area while minimizing cross-sectional area? Well, second moment of area can be maximized by locating as much of the shape as far away from the neutral axis as possible, whereas area can be minimized by squeezing that shape into a thin band.\nWhen bending is expected to occur in only one axis, the best solution is an I-beam. But because this section of the arm has powered rotation about its longitudinal axis, the beam must be able to support an equal load in any direction perpendicular to its length. As such, the cross-sectional shape of choice is a hollow circle, which has the best ratio of second moment of area to area when considering any neutral axis angle.\nArea of a hollow circle: $$ \\begin{equation} A = \\pi(R^2 - r^2) \\end{equation} $$\nSecond moment of area of a hollow circle: $$ \\begin{equation} I = \\frac{\\pi}{4} (R^4 - r^4) \\end{equation} $$\nSecond polar moment of area of a hollow circle: $$ \\begin{equation} J = \\frac{\\pi}{2} (R^4 - r^4) \\end{equation} $$\nEquations Now that we\u0026rsquo;ve simplified the problem down to a cantilever beam with a hollow cylindrical cross-section, we can use several equations that will describe deflection and stress acting on the system.\nShear Stress Max shear stress for a beam with a thin-walled tube [1] $$ \\begin{equation} \\tau_{beam, max} = \\frac{2 F}{A} = \\frac{2 F}{\\pi (R^2 - r^2)} \\end{equation} $$\nShear stress due to torsion for a circular shaft [1] $$ \\begin{equation} \\tau_{torsion} = \\frac{M_x R}{J} = \\frac{F L_y R}{\\frac{\\pi}{2} (R^4 - r^4)} \\end{equation} $$\nCombining the two to get overall max shear stress: $$ \\begin{equation} \\tau_{max} = \\tau_{torsion} + \\tau_{beam, max} \\end{equation} $$\nTensile Stress Max tensile stress for a beam due to bending [1] $$ \\begin{equation} \\sigma_{max} = \\frac{M_y c}{I} = \\frac{F L_x R}{\\frac{\\pi}{4} (R^4 - r^4)} \\end{equation} $$\nDeflection Deflection of a cantilever beam due to a force on the tip [2] $$ \\begin{equation} \\delta_{max} = \\frac{F L_x^3}{3 E I} = \\frac{F L_x^3}{3 E \\frac{\\pi}{4} (R^4 - r^4)} \\end{equation} $$\nOptimization To evaluate this problem holistically, I\u0026rsquo;ve characterized it as an optimization problem. Our objective is to minimize the cross-sectional area (which is proportional to $R^2 - r^2$) as a function of $R$ and $r$.\n$$ \\begin{align} \\min_{R,r} \\quad \u0026amp; R^2 - r^2 \\\\ \\textrm{s.t.} \\quad \u0026amp; \\frac{F L_y R}{\\frac{\\pi}{2} (R^4 - r^4)} \u0026#43; \\frac{2 F}{\\pi (R^2 - r^2)} - \\tau_{max} \\leq 0 \\\\ \u0026amp; F L_x R - \\frac{\\pi}{4} (R^4 - r^4)\\sigma_{max} \\leq 0 \\\\ \u0026amp; F L_x^3 - 3 E \\frac{\\pi}{4} (R^4 - r^4)\\delta_{limit} \\leq 0 \\\\ \u0026amp; r - R \u0026#43; t_{min} \\leq 0 \\\\ \u0026amp; 0.01 \\leq R \\leq 0.075 \\\\ \u0026amp; 0.01 \\leq r \\leq 0.075 \\end{align} $$ Where:\n$t_{min}$ is the minimum thickness chosen by the user. (10) is the shear stress constraint. (11) is the bending stress constraint. (12) is the deflection constraint. (13) limits the minimum wall thickness. (14) and (15) define the min/max dimensions. But before we can see how this performs, we need to choose the material.\nMaterials Let\u0026rsquo;s look at three of the most popular materials when it comes to lightweight structural design: titanium, aluminum, and CFRP. There\u0026rsquo;s a reason these are the top three: strength-to-weight ratio, AKA specific strength.\nMaterial Young\u0026rsquo;s Modulus (Pa) Shear Str (Pa) Yield Str (Pa) Density (kg/m^3) Annealed Grade 5 Titanium 110e9 600e6 910e6 4430 Aluminum 7075-T6 70e9 330e6 480e6 2710 CFRP Tube, 0/90 Ply 132e9 102e6 1745e6 1522 Bear in mind that there CFRP comes in many flavors: different ply orientations, grades of fabric quality, types of epoxy, and fabrication methods. As such, there can be an absolutely staggering amount of variation in material properties between one CFRP product and the next. For simplicity, I am choosing one particular product, a commonly used CFRP tube from Dragonplate.\nWe also need to be extra careful when making theoretical predictions about composites because of their anisotropy. In metals like titanium and aluminum, the yield strength and Young\u0026rsquo;s modulus are basically identical in every direction. But, for example, in CFRP the compressive modulus can be as low as 1/10th of the tensile modulus in some cases. What does this mean for a CFRP beam in bending? Well, a beam in bending is partially in tension and partially in compression, so its equivalent Young\u0026rsquo;s modulus and yield strength are some combination of the composite\u0026rsquo;s tensile and compressive moduli and strengths. This is known as flexural modulus and flexural strength, which is what we should be using here. Furthermore, we should be careful to choose the modulus and strength ratings for the correct ply orientation; in this case 0 degrees.\nAs for minimum wall thickness, I found that deciding on $t_{min}$ was very tricky. In the end, I went with the pragmatic approach of checking the minimum tube thicknesses available online for each material. For titanium and aluminum, that\u0026rsquo;s 0.4064 mm (~1/64\u0026quot;), whereas for CFRP it\u0026rsquo;s 0.762 mm (~0.03\u0026quot;).\nNote that in the real world, risk of impact to the sides of the tube may drive your required wall thickness up.\nResults I used NLOPT, a library for nonlinear optimization, to solve the aforementioned optimization problem. The code can be found here.\nMaterial R (mm) r (mm) Thickness (mm) Mass (kg) Annealed Grade 5 Titanium 34.357 33.972 0.385 0.110 Aluminum 7075-T6 39.463 39.063 0.400 0.0798 CFRP Tube, 0/90 Ply 26.442 25.722 0.719 0.0538 Analysis After looking at the equations from earlier, one\u0026rsquo;s first impression might be that the cylinder radius should jump to the maximum radius possible. This is not the case, because doing so would enlarge the cross-sectional area (and therefore mass) unnecessarily. Instead, it\u0026rsquo;s all about minimum wall thickness. As an example, optimizing inner and outer radii given a specified minimum wall thickness:\nAs previously mentioned, you want to squeeze your geometry into as thin of a band as possible to take advantage of the second moment of area without using up too much cross-sectional area.\nNote that if minimum wall thickness were no object (i.e. you could have infinitesimal walls), then the optimal choice would be to maximize your radius! Sadly, we live in the real world, where we have to care about manufacturability or fabricatability.\nWith the given boundary conditions, the deflection limit is the next deciding factor after minimum wall thickness. As an example, optimizing inner and outer radii given a specified maximum deflection:\nOf course, if the deflection limit is high enough, it becomes irrelevant and the shear and tensile stresses become more important.\nSize vs. Strength I have to admit that I was initially left scratching my head after looking at these plots. After all, why would the optimal titanium beam be heavier than the optimal aluminum beam if the specific strength of titanium is greater?\nRecall Equations (5) through (8): the torsional stress, tensile stress, and deflection are all inversely proportional to the 4th power of the radius.\n$$ \\begin{align*} \\tau_{torsion} \\propto \\frac{1}{R^4} \\end{align*} $$ $$ \\begin{align*} \\sigma_{max} \\propto \\frac{1}{R^4} \\end{align*} $$ $$ \\begin{align*} \\delta_{max} \\propto \\frac{1}{R^4} \\end{align*} $$ On the other hand, area (and therefore mass) is proportional to merely the 2nd power of the radius.\n$$ \\begin{align*} A \\propto R^2 \\end{align*} $$ This means that with increasing radius, stress and deflection drop faster than mass increases!\nNow, does this mean we should just 3D print everything out of foaming PLA? In most cases, absolutely not! First of all, keep in mind that this relationship only holds in situations where second moment of area is important. For example, in bending or buckling as opposed to pure compression or tension.\nIn addition, you will usually have more stringent constraints on the bounding box of the design, and once your maximum radius is sufficiently limited, the material with the higher specific strength will win.\nFor example, optimizing for inner radius $r$ only given a specified maximum outer radius $R$:\nYou can see here that second moment of area dominates the beam moment problem overall, but for sufficiently low $R$, titanium wins.\nSo second moment of area can be more important than specific strength\u0026hellip; provided you have the space to exploit it.\nReferences [1] BasicStressEqns-DBWallace.pdf\n[2] FE Reference Handbook, 9.4 Edition\n","permalink":"https://bbokser.github.io/posts/2023-04-17/","summary":"\u003ch2 id=\"the-problem\"\u003eThe Problem\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s say we need to design a structural section of a robot arm, as shown.\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2023-04-17/arm-diagram.png\"\u003e\u003c/p\u003e\n\u003cp\u003eWe\u0026rsquo;ve been given a few requirements:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe mass of the component must be minimized at all costs.\u003c/li\u003e\n\u003cli\u003eThe length of the link must be 300 mm.\u003c/li\u003e\n\u003cli\u003eThe maximum allowed deflection (caused by the component) is 1 mm.\u003c/li\u003e\n\u003cli\u003eThe combined mass of the maximum payload and end-effector is 30 kg.\u003c/li\u003e\n\u003cli\u003eThe combined center of mass of the payload and end-effector is 50 mm from the joint.\u003c/li\u003e\n\u003cli\u003eBoth the base and end-effector joints can rotate in any axis.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe are allowed to assume that the arm does not move dynamically, so that our analysis can be static-only.\u003c/p\u003e","title":"On the Optimal Design of Cantilever Beams"},{"content":"The new REx Hopper leg parts (which I hinted at in an earlier post) are finally in, and they look great.\nI was worried they\u0026rsquo;d be expensive, but the total cost for all three components shown here (including shipping from China) was only $312.\nAs for the other components, they\u0026rsquo;ve been 3D-printed using Windform XT 2.0, which is supposed to have excellent mechanical properties.\nAnyway, I\u0026rsquo;ve started my new job in Boston, whereas work on the REx Hopper is supposed to continue in Pittsburgh. As such, I\u0026rsquo;ll be directing my design modifications from afar. The project is gradually being transferred into the hands of my former labmates at the REx Lab, who will be running control experiments on the robot.\n","permalink":"https://bbokser.github.io/posts/2023-04-08/","summary":"\u003cp\u003eThe new REx Hopper leg parts (which I hinted at in an earlier post) are finally in, and they look great.\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2023-04-08/machined_1.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003eI was worried they\u0026rsquo;d be expensive, but the total cost for all three components shown here (including shipping from China) was only $312.\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2023-04-08/machined_2.png\"\u003e\u003c/p\u003e\n\u003cp\u003eAs for the other components, they\u0026rsquo;ve been 3D-printed using \u003ca href=\"https://www.windform.com/top-line/windform-xt-2-0/\"\u003eWindform XT 2.0\u003c/a\u003e, which is supposed to have excellent mechanical properties.\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2023-04-08/3dp.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003eAnyway, I\u0026rsquo;ve started my new job in Boston, whereas work on the REx Hopper is supposed to continue in Pittsburgh. As such, I\u0026rsquo;ll be directing my design modifications from afar. The project is gradually being transferred into the hands of my former labmates at the REx Lab, who will be running control experiments on the robot.\u003c/p\u003e","title":"The Parts Are In!"},{"content":"The equations of motion for a robot manipulator and their relationship to the Euler-Lagrange equation are well known in the field of robotics, and yet I was unable to find a single source that provides the derivation. I suppose it\u0026rsquo;s one of those \u0026ldquo;the solution is trivial and is left as an exercise to the reader\u0026rdquo; situations. As such, I\u0026rsquo;m providing one here for dummies like me who need it spelled out step-by-step.\nLet\u0026rsquo;s start with the Euler-Lagrange equation.\n$$ \\begin{equation} \\frac{d}{dt}\\biggl[\\frac{\\partial L}{\\partial\\dot{q}}\\biggr] - \\frac{\\partial L}{\\partial q} = 0 \\end{equation} $$\nNow we add a non-conservative generalized force $\\tau$, which can represent damping or input torque.\n$$ \\begin{equation} \\frac{d}{dt}\\biggl[\\frac{\\partial L}{\\partial\\dot{q}}\\biggr] - \\frac{\\partial L}{\\partial q} = \\tau \\end{equation} $$\nRecall that the Lagrangian $L$ is a function of the vector of generalized coordinates $q(t)$, its time derivative $\\dot{q}(t)$, and time $t$. We typically hide this function notation to keep the equations pretty, but it\u0026rsquo;s important to recognize so that we can perform differential calculus on it.\n$$ \\begin{equation} L = L(q(t), \\dot{q}(t), t) \\end{equation} $$\nRecall also that the Lagrangian is equal to the sum of the kinetic and potential energy terms.\n$$ \\begin{equation} L = T - U \\end{equation} $$\nTaking the partial derivative of that with respect to $q$, we get:\n$$ \\begin{equation} \\frac{\\partial L}{\\partial q} = \\frac{\\partial T}{\\partial q} - \\frac{\\partial U}{\\partial q} \\end{equation} $$\nThis we can plug back into equation 2:\n$$ \\begin{equation} \\frac{d}{dt}\\biggl[\\frac{\\partial L}{\\partial\\dot{q}}\\biggr] - \\frac{\\partial T}{\\partial q} + \\frac{\\partial U}{\\partial q} = \\tau \\end{equation} $$\nAs for the first term, we can use the chain rule to expand it:\n$$ \\begin{equation} \\frac{d}{dt}\\biggl[\\frac{\\partial L}{\\partial\\dot{q}}\\biggr] = \\biggl[\\frac{\\partial^2 L}{\\partial\\dot{q}^2}\\biggr] \\ddot{q} \u0026#43; \\biggl[\\frac{\\partial^2 L}{\\partial q \\partial\\dot{q}}\\biggr]\\dot{q} \u0026#43; \\frac{\\partial}{\\partial t} \\biggl[\\frac{\\partial L}{\\partial \\dot{q}}\\biggr] \\end{equation} $$ Plugging equation 7 back into equation 6, we get:\n$$ \\begin{equation} \\underbrace{\\biggl[\\frac{\\partial^2 L}{\\partial\\dot{q}^2}\\biggr]}_{M} \\ddot{q} \u0026#43; \\underbrace{\\biggl[\\frac{\\partial^2 L}{\\partial q \\partial\\dot{q}}\\biggr]\\dot{q} - \\frac{\\partial T}{\\partial q}}_C \u0026#43; \\underbrace{\\frac{\\partial U}{\\partial q}}_G \u0026#43; \\underbrace{\\frac{\\partial}{\\partial t} \\biggl[\\frac{\\partial L}{\\partial \\dot{q}}\\biggr]}_{\\text{time-varying term}}= \\tau \\end{equation} $$ We can ignore the time derivative term for a time-invariant system (a safe assumption for most robotic manipulators).\n$$ \\begin{equation} \\underbrace{\\biggl[\\frac{\\partial^2 L}{\\partial\\dot{q}^2}\\biggr]}_{M} \\ddot{q} \u0026#43; \\underbrace{\\biggl[\\frac{\\partial^2 L}{\\partial q \\partial\\dot{q}}\\biggr]\\dot{q} - \\frac{\\partial T}{\\partial q}}_C \u0026#43; \\underbrace{\\frac{\\partial U}{\\partial q}}_G = \\tau \\end{equation} $$ $$ \\begin{equation} M(q)\\ddot{q} \u0026#43; C(q, \\dot{q}) \u0026#43; G(q) = \\tau \\end{equation} $$ ","permalink":"https://bbokser.github.io/posts/2023-03-06/","summary":"\u003cp\u003eThe equations of motion for a robot manipulator and their relationship to the Euler-Lagrange equation are well known in the field of robotics, and yet I was unable to find a single source that provides the derivation. I suppose it\u0026rsquo;s one of those \u0026ldquo;the solution is trivial and is left as an exercise to the reader\u0026rdquo; situations. As such, I\u0026rsquo;m providing one here for dummies like me who need it spelled out step-by-step.\u003c/p\u003e","title":"Deriving the Manipulator Equations from the Euler-Lagrange Equation"},{"content":"The REx Hopper is now capable of balancing! However, it suffers from extreme oscillation at a relatively low frequency (about 8 Hz).\nThis looks like a controller issue\u0026ndash;perhaps even a simple matter of gain tuning\u0026ndash;until you look closer and slow the footage down. It\u0026rsquo;s a clear case of mechanical resonance\u0026ndash;notice how much the leg flexes back and forth.\nUnfortunately, I designed this leg with excessive focus on machining cost and ease of assembly, which led to the use of cantilevered joints and the use of, in retrospect, tiny bearings and shoulder screws. As it turns out, what may work for a simple quadruped doesn\u0026rsquo;t apply here. High bending stiffness is crucial for an inverted reaction wheel pendulum.\nWith that lesson learned, I am now finishing up a much improved leg design. This design will not be concerned with cost, but rather purely optimal stiffness and strength-to-weight ratio. Within reason, of course. That means \u0026ldquo;clamshelled\u0026rdquo; aluminum links (to get hollow, near-circular cross-sections, which maximize second moment of area uniformly w.r.t. cross-sectional area) and massive clevis joints.\nHere\u0026rsquo;s a hint at what that looks like (still a W.I.P.):\nOf course, there are ways to circumvent this issue with model-based control. One can model the leg as a set of links with flexible joints. But it\u0026rsquo;s best to just fix this mechanically and leave that as a last resort.\n","permalink":"https://bbokser.github.io/posts/2023-02-17/","summary":"\u003cp\u003eThe REx Hopper is now capable of balancing! However, it suffers from extreme oscillation at a relatively low frequency (about 8 Hz).\u003c/p\u003e\n\u003cp\u003e\u003cdiv style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"\u003e\n      \u003ciframe allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen\" loading=\"eager\" referrerpolicy=\"strict-origin-when-cross-origin\" src=\"https://www.youtube.com/embed/9MAG_7aluU8?autoplay=0\u0026amp;controls=1\u0026amp;end=0\u0026amp;loop=0\u0026amp;mute=0\u0026amp;start=0\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" title=\"YouTube video\"\u003e\u003c/iframe\u003e\n    \u003c/div\u003e\n\n\u003c!-- raw HTML omitted --\u003e\u003c!-- raw HTML omitted --\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/images/2023-02-17/resonance_plot.png\"\u003e\u003c/p\u003e\n\u003cp\u003eThis looks like a controller issue\u0026ndash;perhaps even a simple matter of gain tuning\u0026ndash;until you look closer and slow the footage down. It\u0026rsquo;s a clear case of mechanical resonance\u0026ndash;notice how much the leg flexes back and forth.\u003c/p\u003e","title":"A Lesson in Mechanical Resonance"},{"content":"Over the years, I\u0026rsquo;ve witnessed countless failed projects (many of them my own) resulting from poor self-management. Here is how I recommend one approach hardware projects with the correct mentality.\n1. Don\u0026rsquo;t be Optimistic “I wonder if that would be an issue… eh, it’ll probably be fine.”\n“That could potentially fail, but it probably won’t.”\nNo, It will never be \u0026ldquo;fine\u0026rdquo;. If a thought like that ever passes through your mind you need to STOP RIGHT THERE and correct whatever critical mistake you’re making. No joke. That is a GUARANTEED mistake.\nYou need to consider every possible way in which your design or solution could be flawed, and then realize that it is flawed. Everything that can go wrong will go wrong, and there are ways in which it will go wrong that you are not yet even educated enough to understand.\nBut all of these failure modes can be avoided if you are responsible enough to consider them and then do something about it.\n2. Don\u0026rsquo;t Avoid Unfamiliar Subjects “This is too hard, I’m not going to understand it. Let’s skip this part.”\n“I don’t have time to learn that.”\n\u0026ldquo;I don’t have time to consider that method.”\nAvoidance is an easy trap to fall into because it makes your job simpler and easier. The truth is that if you absolutely need to perform your research carefully and deliberately.\nSolving an engineering problem requires you to learn everything you can about the subject and underlying system. Take notes if you have to. Ask people questions.\nAt the very least, you need to know what you don\u0026rsquo;t know.\nWhat I have found is that most subjects are far easier to understand and quicker to learn than they appear, and yet at the same time they are far more complex than expected. What really holds people back from learning new subjects is not difficulty or time, but fear and sloth.\n3. Don\u0026rsquo;t Get Tunnel Vision “No, I’m sure I can make this work. I can’t consider other options at this point.”\nToo many times have I found myself repetitively performing the same test on a robot, hoping to get drastically better results by slightly modifying parameters. And almost every time, I was forced to snap back to reality because the solution required going far beyond simply tuning parameters. This is tunnel vision. The human brain will do pretty much anything to avoid problem solving and creative thinking. It\u0026rsquo;s scary.\nDon’t get fixated on just one idea. Remember that there are other options, other paths to success. In fact, there is almost always a better way to do something.\n4. Be Wary of Productive Procrastination \u0026ldquo;I need to perfect this before I can move on to the next stage of the project.\u0026rdquo;\nOftentimes when we become intimidated by one aspect of a project, we instead focus on perfecting some other aspect of it, usually a subject we\u0026rsquo;re more comfortable with. This, of course, is just a waste of time. I\u0026rsquo;ve seen engineers (including myself) make this mistake too many times, and it\u0026rsquo;s sad to watch.\nThere’s nothing wrong with perfectionism, but there is always a time limit for completing a project and you need to budget your time appropriately. This is an extension of #2 (Avoidance), but in this case the avoidance is taken one step further. It\u0026rsquo;s an insidious, subconscious form of procrastination, one that allows us to avoid a task while still feeling smart and productive. Don’t fall for this trap.\nLast edited 2025-11-15.\n","permalink":"https://bbokser.github.io/posts/2023-01-24/","summary":"\u003cp\u003eOver the years, I\u0026rsquo;ve witnessed countless failed projects (many of them my own) resulting from poor self-management. Here is how I recommend one approach hardware projects with the correct mentality.\u003c/p\u003e\n\u003ch2 id=\"1--dont-be-optimistic\"\u003e1.  Don\u0026rsquo;t be Optimistic\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e“I wonder if that would be an issue… eh, it’ll probably be fine.”\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e“That could potentially fail, but it probably won’t.”\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eNo, It will never be \u0026ldquo;fine\u0026rdquo;. If a thought like that ever passes through your mind you need to \u003cstrong\u003eSTOP RIGHT THERE\u003c/strong\u003e and correct whatever critical mistake you’re making. No joke. That is a \u003cstrong\u003eGUARANTEED\u003c/strong\u003e mistake.\u003c/p\u003e","title":"How to Not Fail at Hardware Projects"},{"content":"In late 2019, I designed a custom QDD gearbox. Then I designed a bipedal robot with said gearing. By early 2020 I was spending about an hour per day after work coding a controller for the bipedal robot I had designed. In that time I learned a great deal of Python, and my controls proficiency skyrocketed. Then I started grad school and had to put this project on hold for about six months. But now, over a year and a half later, I\u0026rsquo;ve finally achieved stable bipedal walking in simulation.\nOf course, as the saying goes, simulations are doomed to succeed. Successfully transferring Python code controlling a simulated robot to an embedded real-time controller running on a real robot is a monumental task on its own\u0026ndash;just ask Gerardo Bledt. In addition, I\u0026rsquo;ve been dealing with some sort of Bullet physics bug that causes the robot to fly into outer space, which is impeding further progress on the sim. I may have to switch to another simulator, such as RaiSim.\nAnd another thing: I\u0026rsquo;m not entirely satisfied with Spryped\u0026rsquo;s design. I believe many improvements can be made.\n","permalink":"https://bbokser.github.io/posts/2021-07-20/","summary":"\u003cp\u003eIn late 2019, I designed a custom QDD gearbox. Then I designed a bipedal robot with said gearing. By early 2020 I was spending about an hour per day after work coding a controller for the bipedal robot I had designed. In that time I learned a great deal of Python, and my controls proficiency skyrocketed. Then I started grad school and had to put this project on hold for about six months. But now, over a year and a half later, I\u0026rsquo;ve finally achieved stable bipedal walking in simulation.\u003c/p\u003e","title":"Stable Bipedal Walking in Simulation"},{"content":"I have recently implemented a model predictive controller (MPC) to calculate the necessary reaction forces for a legged robot. The work presented here is based on this paper by Kim et al. If you don\u0026rsquo;t know what model predictive control is, I recommend this excellent explanation by Steve Brunton. I also found this guide to model predictive control with CasADI to be extremely helpful. CasADi is an open source nonlinear optimization tool which I\u0026rsquo;m using for MPC.\nHowever, I\u0026rsquo;m not entirely sure yet whether this code works the way it\u0026rsquo;s intended\u0026ndash;I\u0026rsquo;m not getting any error messages, but the force values I\u0026rsquo;m getting seem too low. If you spot anything wrong with my implementation, please let me know.\n​Here\u0026rsquo;s the code.\nPart 1. The Dynamics Formulation From the paper, we have the following discrete dynamics:\n$$ x(k+1) = A_kx(k) + B_k \\hat{f_k} + \\hat{g} $$\nwhere,\n$$ \\begin{equation} x = \\begin{bmatrix} \\theta^{\\top} \u0026amp; p^{\\top} \u0026amp; \\omega^{\\top} \u0026amp; \\dot{p}^{\\top} \\end{bmatrix}^{\\top} \\end{equation} $$\n$$ \\begin{equation} \\hat{f} = \\begin{bmatrix} f_1 \u0026amp; \u0026hellip; \u0026amp; f_n \\end{bmatrix}^{\\top} \\end{equation} $$\n$$ \\begin{equation} \\hat{g} = \\begin{bmatrix} 0_{1\\times{}3} \u0026amp; 0_{1\\times{}3} \u0026amp; 0_{1\\times{}3} \u0026amp; g^{\\top} \\end{bmatrix}^{\\top} \\end{equation} $$\n$$ \\begin{equation} A = \\begin{bmatrix} 1_{3\\times3} \u0026amp; 0_{3\\times3} \u0026amp; R_z(\\psi)\\Delta t \u0026amp; 0_{3\\times3} \\newline 0_{3\\times3} \u0026amp; 1_{3\\times3} \u0026amp; 0_{3\\times3} \u0026amp; 1_{3\\times3} \\Delta t \\newline 0_{3\\times3} \u0026amp; 0_{3\\times3} \u0026amp; 1_{3\\times3} \u0026amp; 0_{3\\times3} \\newline 0_{3\\times3} \u0026amp; 0_{3\\times3} \u0026amp; 0_{3\\times3} \u0026amp; 1_{3\\times3} \\end{bmatrix} \\end{equation} $$\n$$ \\begin{equation} B = \\begin{bmatrix} 0_{3\\times3} \u0026amp; 0_{3\\times3} \\newline 0_{3\\times3} \u0026amp; 0_{3\\times3} \\newline {}_GI^{-1}[r_1]_\\times \\Delta t \u0026amp; {}_GI^{-1}[r_1]_\\times \\Delta t \\newline 1_{3\\times3} \\Delta t /m \u0026amp; 1_{3\\times3} \\Delta t /m \\end{bmatrix} \\end{equation} $$ First off, you may be wondering what this notation means.\n$[r_1]_\\times$ refers to a skew-symmetric matrix. The $3\\times1$ vectors $r_1$ and $r_2$ (footstep positions) are converted into a $3\\times3$ matrix in order to perform a cross product operation with the inverse of the global inertia tensor.\n% matlab code r = [[0, -r_z, r_y]; [r_z, 0, -r_x]; [-r_y, r_x, 0]]; i_inv = sym(\u0026#39;i\u0026#39;, [3, 3]); mtimes(i_inv, r) A few more notes:\nThe state term $x$ is a $12\\times1$ vector composed of the angle, position, angular velocity, and velocity of the body w.r.t. to the global frame. In my case, there are only two legs, so there six scalar control values: $f_{1x}$, $f_{1y}$, $f_{1z}$, $f_{2x}$, $f_{2y}$, $f_{2z}$. The gravity term $\\hat{g}$ is a $12\\times1$ vector of zeros until the last term, which is the gravitational constant. $R_z$ is a $3\\times3$ rotation matrix for translating angular velocity from the global frame to the body frame. % matlab code syms theta_x theta_y theta_z p_x p_y p_z omega_x omega_y omega_z pdot_x ... pdot_y pdot_z f1_x f1_y f1_z f2_x f2_y f2_z ... dt i_inv r1x r1y r1z r2x r2y r2z mass gravity... i11 i12 i13 i21 i22 i23 i31 i32 i33... rz11 rz12 rz13 rz21 rz22 rz23 rz31 rz32 rz33 x = [[theta_x]; % states [theta_y]; [theta_z]; [p_x]; [p_y]; [p_z]; [omega_x]; [omega_y]; [omega_z]; [pdot_x]; [pdot_y]; [pdot_z]]; f = [[f1_x]; % controls [f1_y]; [f1_z]; [f2_x]; [f2_y]; [f2_z]]; g = [[0]; [0]; [0]; [0]; [0]; [0]; [0]; [0]; [0]; [0]; [0]; [gravity]]; A = [[1, 0, 0, 0, 0, 0, rz11*dt, rz12*dt, rz13*dt, 0, 0, 0]; [0, 1, 0, 0, 0, 0, rz21*dt, rz22*dt, rz23*dt, 0, 0, 0]; [0, 0, 1, 0, 0, 0, rz31*dt, rz32*dt, rz33*dt, 0, 0, 0]; [0, 0, 0, 1, 0, 0, 0, 0, 0, dt, 0, 0]; [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, dt, 0]; [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, dt]; [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]; [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]; [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]; [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]; [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]; [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]; B = [[0, 0, 0, 0, 0, 0]; [0, 0, 0, 0, 0, 0]; [0, 0, 0, 0, 0, 0]; [0, 0, 0, 0, 0, 0]; [0, 0, 0, 0, 0, 0]; [0, 0, 0, 0, 0, 0]; [(i12*r1z - i13*r1y)*dt, (-i11*r1z + i13*r1x)*dt, (i11*r1y - i12*r1x)*dt, ... (i12*r2z - i13*r2y)*dt, (-i11*r2z + i13*r2x)*dt, (i11*r2y - i12*r2x)*dt]; [(i22*r1z - i23*r1y)*dt, (-i21*r1z + i23*r1x)*dt, (i21*r1y - i22*r1x)*dt, ... (i22*r2z - i23*r2y)*dt, (-i21*r2z + i23*r2x)*dt, (i21*r2y - i22*r2x)*dt]; [(i32*r1z - i33*r1y)*dt, (-i31*r1z + i33*r1x)*dt, (i31*r1y - i32*r1x)*dt, ... (i32*r2z - i33*r2y)*dt, (-i31*r2z + i33*r2x)*dt, (i31*r2y - i32*r2x)*dt]; [dt/mass, 0, 0, dt/mass, 0, 0]; [0, dt/mass, 0, 0, dt/mass, 0]; [0, 0, dt/mass, 0, 0, dt/mass]]; x_next = mtimes(A, x) + mtimes(B, f) + g; The end result is a very long equation which will be used as a constraint for the QP. The states and controls are defined as symbolics, but other values such as the inertia tensor, rotation matrix, and foot positions are fed in as numerical values from sensor feedback.\n# python gravity = -9.807 dt = self.dt mass = self.mass x_next = [dt * omega_x * rz11 + dt * omega_y * rz12 + dt * omega_z * rz13 + theta_x, dt * omega_x * rz21 + dt * omega_y * rz22 + dt * omega_z * rz23 + theta_y, dt * omega_x * rz31 + dt * omega_y * rz32 + dt * omega_z * rz33 + theta_z, dt * pdot_x + p_x, dt * pdot_y + p_y, dt * pdot_z + p_z, dt * f1_x * (i12 * r1z - i13 * r1y) + dt * f1_y * (-i11 * r1z + i13 * r1x) + dt * f1_z * (i11 * r1y - i12 * r1x) + dt * f2_x * (i12 * r2z - i13 * r2y) + dt * f2_y * (-i11 * r2z + i13 * r2x) + dt * f2_z * (i11 * r2y - i12 * r2x) + omega_x, dt * f1_x * (i22 * r1z - i23 * r1y) + dt * f1_y * (-i21 * r1z + i23 * r1x) + dt * f1_z * (i21 * r1y - i22 * r1x) + dt * f2_x * (i22 * r2z - i23 * r2y) + dt * f2_y * (-i21 * r2z + i23 * r2x) + dt * f2_z * (i21 * r2y - i22 * r2x) + omega_y, dt * f1_x * (i32 * r1z - i33 * r1y) + dt * f1_y * (-i31 * r1z + i33 * r1x) + dt * f1_z * (i31 * r1y - i32 * r1x) + dt * f2_x * (i32 * r2z - i33 * r2y) + dt * f2_y * (-i31 * r2z + i33 * r2x) + dt * f2_z * (i31 * r2y - i32 * r2x) + omega_z, dt * f1_x / mass + dt * f2_x / mass + pdot_x, dt * f1_y / mass + dt * f2_y / mass + pdot_y, dt * f1_z / mass + dt * f2_z / mass + gravity + pdot_z] self.fn = cs.Function(\u0026#39;fn\u0026#39;, [theta_x, theta_y, theta_z, p_x, p_y, p_z, omega_x, omega_y, omega_z, pdot_x, pdot_y, pdot_z, f1_x, f1_y, f1_z, f2_x, f2_y, f2_z], x_next) # nonlinear mapping of function f(x,u) Part 2. The Objective Function $$ \\begin{align} \\min_{x,f} \\quad \u0026amp; \\sum^{m}_{k=0} \\lVert x(k+1) - x^{ref}(k+1) \\lVert_Q + \\lVert f_k\\lVert_R \\end{align} $$\nThe objective function is shown above.\n$$ \\lVert f(k)\\lVert_R $$\nLet\u0026rsquo;s start with this notation. What does it mean? Well, double bars represent a matrix norm. However, the R in subscript clues us into the fact that this is a special case of the matrix norm with an inner product. Q and R are weighing matrices and should be diagonal.\n$$ \\begin{equation} \\lVert f(k)\\lVert_R = \\sqrt{f(k)_R} = \\sqrt{f(k)*R*f(k)} \\end{equation} $$ However, I\u0026rsquo;m not sure what the purpose of the square root would be here. It seems to me that minimizing the square root of $f(x)$ is basically equivalent to minimizing $f(x)$ by itself, but more computationally expensive. In fact, running the code with the square root operation actually causes a QP is infeasible! error. As such, I\u0026rsquo;m leaving the square root operation out.\nSo, the objective function minimizes $x$ and $f$ (the state and control vectors) based on the difference between actual and reference state as well as the value of $f$, scaled to Q and R respectively, over $k$ time steps where $k$ is between 0 and $m$. Here, $m$ refers to the prediction horizon, which is chosen by the user.\nu = cs.SX.sym(\u0026#39;u\u0026#39;, self.n_controls, self.N) # decision variables, control action matrix st_ref = cs.SX.sym(\u0026#39;st_ref\u0026#39;, self.n_states + self.n_states) # initial and reference states x = cs.SX.sym(\u0026#39;x\u0026#39;, self.n_states, (self.N + 1)) # represents the states over the opt problem. obj = 0 # cs.SX(0) # objective function constr = [] # constraints vector Q = np.zeros((12, 12)) # state weighing matrix Q[0, 0] = 1 Q[1, 1] = 1 Q[2, 2] = 1 Q[3, 3] = 1 Q[4, 4] = 1 Q[5, 5] = 1 Q[6, 6] = 1 Q[7, 7] = 1 Q[8, 8] = 1 Q[9, 9] = 1 Q[10, 10] = 1 Q[11, 11] = 1 R = np.zeros((6, 6)) # control weighing matrix R[0, 0] = 1 R[1, 1] = 1 R[2, 2] = 1 R[3, 3] = 1 R[4, 4] = 1 R[5, 5] = 1 st = x[:, 0] # initial state constr = cs.vertcat(constr, st - st_ref[0:self.n_states]) # initial condition constraints # compute objective and constraints for k in range(0, self.N): st = x[:, k] # state con = u[:, k] # control action # calculate objective obj = obj + cs.mtimes(cs.mtimes((st - st_ref[self.n_states:(self.n_states * 2)]).T, Q), st - st_ref[self.n_states:(self.n_states * 2)])) \\ + cs.mtimes(cs.mtimes(con.T, R), con)) Both my Q and R are identity matrices right now, as I have not yet tuned them.\nPart 3. The Constraints Vector In the same for loop, we can now add the constraints vector. For each iteration of the loop, the discrete dynamics equation from Part 1 is subtracted from the next state vector, $x(k+1)$.\nfor k in range(0, self.N): # ... st_next = x[:, k + 1] f_value = self.fn(st[0], st[1], st[2], st[3], st[4], st[5], st[6], st[7], st[8], st[9], st[10], st[11], con[0], con[1], con[2], con[3], con[4], con[5]) st_n_e = np.array(f_value) constr = cs.vertcat(constr, st_next - st_n_e) # compute constraints There are more constraints, however. Namely, friction cone constraints, governed by friction of the feet with the ground. As stated in the paper:\n$$ \\begin{equation} \\vert{}f_x\\vert{} \\leq \\mu f_z \\end{equation} $$\n$$ \\begin{equation} \\vert{}f_x\\vert{} \\leq \\mu f_z \\end{equation} $$\n$$ \\begin{equation} f_z \u0026gt; 0 \\end{equation} $$\nHere\u0026rsquo;s my implementation below. Both the $F_x$ and $F_y$ inequalities must be repeated due to the absolute value function. $F_z$ is not required here because it\u0026rsquo;s extremely simple and can be implemented as an input constraint.\n# add additional constraints for k in range(0, self.N): constr = cs.vertcat(constr, u[0, k] - self.mu * u[2, k]) # f1x - mu*f1z constr = cs.vertcat(constr, -u[0, k] - self.mu * u[2, k]) # -f1x - mu*f1z constr = cs.vertcat(constr, u[1, k] - self.mu * u[2, k]) # f1y - mu*f1z constr = cs.vertcat(constr, -u[1, k] - self.mu * u[2, k]) # -f1y - mu*f1z constr = cs.vertcat(constr, u[3, k] - self.mu * u[5, k]) # f2x - mu*f2z constr = cs.vertcat(constr, -u[3, k] - self.mu * u[5, k]) # -f2x - mu*f2z constr = cs.vertcat(constr, u[4, k] - self.mu * u[5, k]) # f2y - mu*f2z constr = cs.vertcat(constr, -u[4, k] - self.mu * u[5, k]) # -f2y - mu*f2z Part 4. Problem Setup The solver used here is qpOASES. The optimization variables (in this case, the state and controls), objective function, constraint functions, and reference state are declared as shown. It is important to specify a bound tolerance and termination tolerance.\nopt_variables = cs.vertcat(cs.reshape(x, n_states * (self.N + 1), 1), cs.reshape(u, n_controls * self.N, 1)) qp = {\u0026#39;x\u0026#39;: opt_variables, \u0026#39;f\u0026#39;: obj, \u0026#39;g\u0026#39;: constr, \u0026#39;p\u0026#39;: st_ref} opts = {\u0026#39;print_time\u0026#39;: 0, \u0026#39;error_on_fail\u0026#39;: 0, \u0026#39;printLevel\u0026#39;: \u0026#34;low\u0026#34;, \u0026#39;boundTolerance\u0026#39;: 1e-6, \u0026#39;terminationTolerance\u0026#39;: 1e-6} solver = cs.qpsol(\u0026#39;S\u0026#39;, \u0026#39;qpoases\u0026#39;, qp, opts) Part 5. Upper and Lower Bounds The upper and lower bounds for the constraint vector still needs to be set. The dynamics equation is set up as an equality constraint, so the upper and lower bounds are both zero. The initial condition constraint is also an equality constraint, since the first state vector must be equal to the input state vector. The rest of the constraints have a lower bound close to infinity.\nc_length = np.shape(constr)[0] o_length = np.shape(opt_variables)[0] lbg = list(itertools.repeat(-1e10, c_length)) # inequality constraints: big enough to act like infinity lbg[0:(self.N + 1)] = itertools.repeat(0, self.N + 1) # IC + dynamics equality constraint ubg = list(itertools.repeat(0, c_length)) # inequality constraints Constraints for the optimization variables are set separately. This is where the friction cone restraint for $F_z$ comes into play. The reaction force perpendicular to the ground (assumed flat) must be upward, because the robot can only push itself away from the ground rather than pull itself toward the ground. Therefore, the lower bound on all $F_z$ is 0.\nAdditionally, the MPC must check if each leg is actually in contact with the ground when calculating forces for it. If that leg is not in contact, all bounds are set equal to zero.\n# constraints for optimization variables lbx = list(itertools.repeat(-1e10, o_length)) # input inequality constraints ubx = list(itertools.repeat(1e10, o_length)) # input inequality constraints dyn_len = self.n_states * (self.N + 1) lbx[(dyn_len + 2)::3] = [0 for i in range(20)] # lower bound on all f1z and f2z if c_l == 0: # if left leg is not in contact... don\u0026#39;t calculate output forces for that leg. ubx[(self.n_states * (self.N + 1))::6] = [0 for i in range(10)] # upper bound on all f1x ubx[(self.n_states * (self.N + 1) + 1)::6] = [0 for i in range(10)] # upper bound on all f1y lbx[(self.n_states * (self.N + 1))::6] = [0 for i in range(10)] # lower bound on all f1x lbx[(self.n_states * (self.N + 1) + 1)::6] = [0 for i in range(10)] # lower bound on all f1y ubx[(self.n_states * (self.N + 1) + 2)::6] = [0 for i in range(10)] # upper bound on all f1z if c_r == 0: # if right leg is not in contact... don\u0026#39;t calculate output forces for that leg. ubx[(self.n_states * (self.N + 1) + 3)::6] = [0 for i in range(10)] # upper bound on all f2x ubx[(self.n_states * (self.N + 1) + 4)::6] = [0 for i in range(10)] # upper bound on all f2y lbx[(self.n_states * (self.N + 1) + 3)::6] = [0 for i in range(10)] # lower bound on all f2x lbx[(self.n_states * (self.N + 1) + 4)::6] = [0 for i in range(10)] # lower bound on all f2y ubx[(self.n_states * (self.N + 1) + 5)::6] = [0 for i in range(10)] # upper bound on all f2z Part 6. Solving Firstly, initial values must be fed into the solver.\nI\u0026rsquo;ve set the initial values for my control inputs as an array of zeros, although I\u0026rsquo;m wondering if that should really be the last set of control inputs applied.\nThe initial values for the state are pulled in and calculated from the simulator. This $12\\times1$ array is repeated $N+1$ times, where $N$ is the prediction horizon, in order to fill the entire array including future states.\nu0 = np.zeros((self.N, self.n_controls)) # six control inputs X0 = np.matlib.repmat(x_in, 1, self.N + 1).T # initialization of the state\u0026#39;s decision variables parameters = cs.vertcat(x_in, x_ref) # set values of parameters vector # init value of optimization variables x0 = cs.vertcat(np.reshape(X0.T, (self.n_states * (self.N + 1), 1)), np.reshape(u0.T, (self.n_controls * self.N, 1))) Finally, the initial states, bounds, and parameters are plugged into the solver. The controls vector is pulled from the solution, and the first row of optimized control values is returned. The rest of the values (representing future time steps) are ignored.\nsol = solver(x0=x0, lbx=lbx, ubx=ubx, lbg=lbg, ubg=ubg, p=parameters) solu = np.array(sol[\u0026#39;x\u0026#39;][self.n_states * (self.N + 1):]) u = np.reshape(solu.T, (self.n_controls, self.N)).T # get controls from the solution u_cl = u[0, :] # ignore rows other than first row return u_cl ","permalink":"https://bbokser.github.io/posts/2020-10-12/","summary":"\u003cp\u003eI have recently implemented a model predictive controller (MPC) to calculate the necessary reaction forces for a legged robot. The work presented here is based on \u003ca href=\"https://arxiv.org/pdf/1909.06586.pdf\"\u003ethis\u003c/a\u003e paper by Kim et al. If you don\u0026rsquo;t know what model predictive control is, I recommend \u003ca href=\"https://youtu.be/YwodGM2eoy4\"\u003ethis\u003c/a\u003e excellent explanation by Steve Brunton. I also found \u003ca href=\"https://youtu.be/RrnkPrcpyEA\"\u003ethis\u003c/a\u003e guide to model predictive control with CasADI to be extremely helpful. CasADi is an open source nonlinear optimization tool which I\u0026rsquo;m using for MPC.\u003c/p\u003e","title":"Model Predictive Control for a Legged Robot"},{"content":"I\u0026rsquo;m currently working on the Python code to control a simulated version of my latest bipedal robot design in PyBullet. My focus over the past few weeks was getting the operational space control to work (many thanks to Travis DeWolf\u0026rsquo;s incredibly helpful blog). After finally getting it to work properly, I have decided to share my math in the hopes of providing a useful example for anyone else having trouble with this. There really aren\u0026rsquo;t enough resources on the internet that explain this in a succinct manner.\nSolving for the transformation matrices and centers of motion correctly is the trickiest part of the process, and deceptively so. For more information on how to set up the transformation matrices, I recommend this Youtube tutorial and this blog post.\nI find it easiest to solve for the transformation matrices by \u0026ldquo;stringing\u0026rdquo; the robot out, as shown below, such that all of the joints\u0026rsquo; coordinate systems are oriented the same way. This saves you from having to perform additional linear algebra operations, which would raise your chances of making a mistake.\nShown below are the transformation matrices. The first transformation represents an x-axis rotation. See the first joint in the kinematic diagram above for reference. Transformations (2) through (4) are z-axis rotations. Despite the z-axis pointing up in the world coordinate system, the default angle (90 degrees) for the first x-axis rotation points the z-axis of the second through fourth joints parallel to the y-axis of the WCS.\n$$ \\begin{equation} {}_{org}^0 T = \\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; \\cos{(q_{0})} \u0026amp; - \\sin{(q_{0})} \u0026amp; L_{0}\\cos{(q_{0})} \\newline 0 \u0026amp; \\sin{(q_{0})} \u0026amp; \\cos{(q_{0})} \u0026amp; L_{0}\\sin{(q_{0})} \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix}\t\\end{equation} $$ $$ \\begin{equation} {}_0^1 T = \\begin{bmatrix} \\cos{(q_{1} )} \u0026amp; - \\sin{(q_{1} )} \u0026amp; 0 \u0026amp; -L_{1} \\sin{(q_{1} )} \\newline \\sin{(q_{1} )} \u0026amp; \\cos{(q_{1} )} \u0026amp; 0 \u0026amp; L_{1} \\cos{(q_{1} )} \\newline 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} \\end{equation} $$ $$ \\begin{equation} {}_1^2 T = \\begin{bmatrix} \\cos{(q_{2} )} \u0026amp; - \\sin{(q_{2} )} \u0026amp; 0 \u0026amp; -L_{2} \\sin{(q_{2} )} \\newline \\sin{(q_{2} )} \u0026amp; \\cos{(q_{2} )} \u0026amp; 0 \u0026amp; L_{2} \\cos{(q_{2} )} \\newline 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} \\end{equation} $$ $$ \\begin{equation} {}_2^3 T = \\begin{bmatrix} \\cos{(q_{3} )} \u0026amp; - \\sin{(q_{3} )} \u0026amp; 0 \u0026amp; -L_{3} \\sin{(q_{3} )} \\newline \\sin{(q_{3} )} \u0026amp; \\cos{(q_{3} )} \u0026amp; 0 \u0026amp; L_{3} \\cos{(q_{3} )} \\newline 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} \\end{equation} $$ Next, the locations for the centers of mass at each link are found, where $l_0$, $l_1$, $l_2$, and $l_3$ represent the distance of the center of mass from the base joint of each link, along a line connecting the base joint to the next joint. Keep in mind that the centers of mass may not be located directly along a line from one joint to the next in any given robot link, and that in this case I am able to make this approximation for the purpose of mathematical simplicity.\n$$ \\begin{equation} com_0 = \\begin{bmatrix} 0 \\newline l_{0} \\cos{(q_{0} )} \\newline l_{0} \\sin{(q_{0} )} \\newline 1 \\end{bmatrix} \\end{equation} $$\n$$ \\begin{equation} com_1 = \\begin{bmatrix} {-l_{1} \\sin{(q_{1} )}} \\newline l_{1} \\cos{(q_{1} )} \\newline 0 \\newline 1 \\end{bmatrix} \\end{equation} $$\n$$ \\begin{equation} com_2 = \\begin{bmatrix} -l_{2} \\sin{(q_{2} )} \\newline l_{2} \\cos{(q_{2} )} \\newline 0 \\newline 1 \\end{bmatrix} \\end{equation} $$\n$$ \\begin{equation} com_3 = \\begin{bmatrix} -l_{3} \\sin{(q_{3} )} \\newline l_{3} \\cos{(q_{3} )} \\newline 0 \\newline 1 \\end{bmatrix} \\end{equation} $$\nThe end-effector offset (Equation 9) should also be kept in mind, but in my case I don\u0026rsquo;t need an offset from the end-effector. As such, I\u0026rsquo;m expressing it as zero.\n$$ \\begin{equation} x_{ee} = \\begin{bmatrix} 0 \\newline 0 \\newline 0 \\newline 1 \\end{bmatrix} \\end{equation} $$\nNext, I solved for the full transformation matrices from the origin to each joint. This isn\u0026rsquo;t necessary for the first joint, because it\u0026rsquo;s already in the base coordinate system.\n$$ \\begin{equation} _{org}^1 T = _{org}^0 T _0^1 T \\end{equation} $$\n$$ \\begin{equation} _{org}^2 T = _{org}^0 T _0^1 T _1^2 T \\end{equation} $$\n$$ \\begin{equation} _{org}^3 T = _{org}^0 T _0^1 T _1^2 T _2^3 T \\end{equation} $$\nNow, the Jacobian for each COM and the end-effector can be found as a matrix of its partial derivatives with respect to each joint qᵢ. Both linear and angular velocities must be accounted for, so I have $x$, $y$, $z$, $\\omega_x$, $\\omega_y$, $\\omega_z$ to deal with.\n$$ \\begin{equation} Jacobian = \\begin{bmatrix} \\frac{\\partial x}{\\partial q_0} \u0026amp; \\frac{\\partial x}{\\partial q_1} \u0026amp; \\frac{\\partial x}{\\partial q_2} \u0026amp; \\frac{\\partial x}{\\partial q_3} \\newline \\frac{\\partial y}{\\partial q_0} \u0026amp; \\frac{\\partial y}{\\partial q_1} \u0026amp; \\frac{\\partial y}{\\partial q_2} \u0026amp; \\frac{\\partial y}{\\partial q_3} \\newline \\frac{\\partial z}{\\partial q_0} \u0026amp; \\frac{\\partial z}{\\partial q_1} \u0026amp; \\frac{\\partial z}{\\partial q_2} \u0026amp; \\frac{\\partial z}{\\partial q_3} \\newline \\frac{\\partial \\omega_x}{\\partial q_0} \u0026amp; \\frac{\\partial \\omega_x}{\\partial q_1} \u0026amp; \\frac{\\partial \\omega_x}{\\partial q_2} \u0026amp; \\frac{\\partial \\omega_x}{\\partial q_3} \\newline \\frac{\\partial \\omega_y}{\\partial q_0} \u0026amp; \\frac{\\partial \\omega_y}{\\partial q_1} \u0026amp; \\frac{\\partial \\omega_y}{\\partial q_2} \u0026amp; \\frac{\\partial \\omega_y}{\\partial q_3} \\newline \\frac{\\partial \\omega_z}{\\partial q_0} \u0026amp; \\frac{\\partial \\omega_z}{\\partial q_1} \u0026amp; \\frac{\\partial \\omega_z}{\\partial q_2} \u0026amp; \\frac{\\partial \\omega_z}{\\partial q_3} \\newline \\end{bmatrix} \\end{equation} $$ So far I haven\u0026rsquo;t explained angular velocity. This I have solved separately, and it\u0026rsquo;s quite simple as long as your robot is serial and doesn\u0026rsquo;t have spherical joints. The partial derivative for the angular velocity w.r.t. each joint is expressed as 1 if that joint rotates along that axis, and 0 if it doesn\u0026rsquo;t. For example, in J₀ (Equation 14), joint q₀ rotates around the x axis, so the partial derivative of $\\omega_x$ w.r.t. $q_0$ is 1. In $J_1$ (Equation 15), joint $q_1$ rotates about the z axis, so the partial derivative of $\\omega_z$ w.r.t. $q_1$ is 1.\n$$ \\begin{equation} J_0 = Jacobian(com_0) = \\begin{bmatrix} 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline - l_{0} \\sin{(q_{0} )} \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline l_{0} \\cos{(q_{0} )} \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix} \\end{equation} $$ I can only show the first two Jacobians here, as the rest are too long to fit on the screen. You\u0026rsquo;ll notice that the Jacobians for the centers of motion of each link ($J_0$, $J_1$, $J_2$, and $J_3$) are calculated as a function of the transformation matrix from the link\u0026rsquo;s base joint to the origin multiplied by that link\u0026rsquo;s center of motion. This confused me the first time around, and I don\u0026rsquo;t want you, the reader, to make the same mistake.\nFor example, in the case of $J_1$ (the Jacobian for the second link), the transformation matrix from joint 0 to the world coordinate frame (origin) is multiplied by $com_1$, the center of motion of the link between joints 0 and 1 (the first and second joints, so the second link).\nFor $J_0$ (the Jacobian for the first link), no transformation matrix is required because the first joint ($q_0$) is already in the base coordinate system.\nI\u0026rsquo;m probably just confusing you more because my joint indexing starts at zero, but that\u0026rsquo;s for programming purposes and is standard\u0026hellip;\n$$ J_1 = Jacobian(_{org}^0 T com_1) = $$\n$$ \\begin{equation} \\begin{bmatrix} 0 \u0026amp; - l_{1} \\cos{(q_{1} )} \u0026amp; 0 \u0026amp; 0 \\newline - (L_{0} + l_{1} \\cos{(q_{1} )}) \\sin{(q_{0} )} \u0026amp; - l_{1} \\sin{(q_{1} )} \\cos{(q_{0} )} \u0026amp; 0 \u0026amp; 0 \\newline (L_{0} + l_{1} \\cos{(q_{1} )}) \\cos{(q_{0} )} \u0026amp; - l_{1} \\sin{(q_{0} )} \\sin{(q_{1} )} \u0026amp; 0 \u0026amp; 0 \\newline 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix} \\end{equation} $$\n$$ \\begin{equation} J_2 = Jacobian(_{org}^1 T com_2) \\end{equation} $$\n$$ \\begin{equation} J_3 = Jacobian(_{org}^2 T com_3) \\end{equation} $$\n$$ \\begin{equation} J_{EE} = Jacobian(_{org}^3 T x_{ee}) \\end{equation} $$ So there you have it. After several headaches, I was able to verify that this setup works in simulation. The chief cause of my problems was that I had solved for the transformation matrices incorrectly! Everything else is easy\u0026ndash;though it looks intimidating, all of the symbolic math can be computationally solved by Matlab/Octave. Just remember\u0026hellip;\n$$ \\begin{equation} \\text{garbage}_{in} = \\text{garbage}_{out} \\end{equation} $$ ","permalink":"https://bbokser.github.io/posts/2020-05-04/","summary":"\u003cp\u003eI\u0026rsquo;m currently working on the Python \u003ca href=\"https://github.com/bbokser/spryped\"\u003ecode\u003c/a\u003e to control a simulated version of my latest bipedal robot design in PyBullet. My focus over the past few weeks was getting the operational space control to work (many thanks to Travis DeWolf\u0026rsquo;s incredibly helpful \u003ca href=\"https://studywolf.wordpress.com/site-index/\"\u003eblog\u003c/a\u003e). After finally getting it to work properly, I have decided to share my math in the hopes of providing a useful example for anyone else having trouble with this. There really aren\u0026rsquo;t enough resources on the internet that explain this in a succinct manner.\u003c/p\u003e","title":"Solving for the Jacobians of a Robot Leg"}]